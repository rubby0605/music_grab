#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Discord Botï¼š
  1. ä¸Šå‚³ PDF/DOCX â†’ AI æ‘˜è¦ â†’ MP3 èªéŸ³
  2. è²¼ YouTube URL â†’ é‹¼ç´æ¨‚è­œ PDF + MIDI
"""

import os
import re
import tempfile
import asyncio
import functools
import shutil
import subprocess
import discord
from openai import OpenAI
from newslib import read_docx, read_pdf, chunk_text
import pretty_midi
import numpy as np
import librosa
from piano_transcription_inference import PianoTranscription, sample_rate as PT_SR, load_audio

DISCORD_TOKEN = os.environ.get('DISCORD_BOT_TOKEN', '')
SUPPORTED_EXT = ('.pdf', '.docx')
VIDEO_EXT = ('.mp4', '.mkv', '.avi', '.mov', '.webm')
DISCORD_MAX_BYTES = 8 * 1024 * 1024  # æœªåŠ æˆä¼ºæœå™¨ä¸Šé™ 8MB
YT_URL_PATTERN = re.compile(
    r'(https?://)?(www\.)?(youtube\.com/watch\?v=|youtu\.be/|youtube\.com/shorts/)[\w\-]+'
)

intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)


# â”€â”€ TTS åŠŸèƒ½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def summarize_text(text):
    openai_client = OpenAI()
    max_input = 12000
    system_msg = (
        'ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡ä»¶æ‘˜è¦åŠ©ç†ã€‚'
        'è«‹å°‡ä»¥ä¸‹æ–‡ä»¶å…§å®¹æ¶ˆåŒ–æ•´ç†æˆé©åˆèªéŸ³æ’­å ±çš„æ–‡ç¨¿ã€‚'
        'è¦æ±‚ï¼šä¿ç•™é‡è¦è³‡è¨Šå’Œé—œéµæ•¸æ“šã€å»é™¤æ ¼å¼é›œè¨Šã€å£èªåŒ–ã€ç¹é«”ä¸­æ–‡ã€ä¸åŠ å‰è¨€ã€‚'
    )
    if len(text) > max_input:
        segments = [text[i:i+max_input] for i in range(0, len(text), max_input)]
        summaries = []
        for i, seg in enumerate(segments):
            resp = openai_client.chat.completions.create(
                model='gpt-4o-mini', temperature=0.3,
                messages=[
                    {'role': 'system', 'content': system_msg},
                    {'role': 'user', 'content': f'ç¬¬ {i+1}/{len(segments)} éƒ¨åˆ†ï¼š\n\n{seg}'}
                ])
            summaries.append(resp.choices[0].message.content)
        return '\n\n'.join(summaries)
    else:
        resp = openai_client.chat.completions.create(
            model='gpt-4o-mini', temperature=0.3,
            messages=[{'role': 'system', 'content': system_msg}, {'role': 'user', 'content': text}])
        return resp.choices[0].message.content


def tts_single_chunk(text, output_path, voice='alloy', model='tts-1'):
    openai_client = OpenAI()
    response = openai_client.audio.speech.create(model=model, voice=voice, input=text)
    response.stream_to_file(output_path)


def convert_all_chunks(chunks, tmpdir, voice='alloy', model='tts-1'):
    part_paths = []
    for i, chunk in enumerate(chunks):
        part_path = os.path.join(tmpdir, f'part_{i}.mp3')
        tts_single_chunk(chunk, part_path, voice=voice, model=model)
        part_paths.append(part_path)
    merged_path = os.path.join(tmpdir, 'merged.mp3')
    with open(merged_path, 'wb') as out:
        for p in part_paths:
            with open(p, 'rb') as f:
                out.write(f.read())
    return merged_path, part_paths


# â”€â”€ æ¨‚è­œåŠŸèƒ½ï¼ˆOpenAI GPT-4o Audioï¼‰â”€â”€â”€â”€â”€â”€â”€â”€

def yt_get_title(url):
    try:
        r = subprocess.run(['yt-dlp', '--get-title', '--no-playlist', url],
                           capture_output=True, text=True, timeout=30)
        return r.stdout.strip()[:60] or 'Untitled'
    except Exception:
        return 'Untitled'


def yt_download_video(url, tmpdir):
    """YouTube â†’ MP4 å½±ç‰‡"""
    output_path = os.path.join(tmpdir, 'video.%(ext)s')
    r = subprocess.run(
        ['yt-dlp', '-f', 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
         '--merge-output-format', 'mp4',
         '-o', output_path, '--no-playlist', url],
        capture_output=True, text=True, timeout=600)
    if r.returncode != 0:
        raise RuntimeError(f'yt-dlp å¤±æ•—: {r.stderr[-300:]}')
    for f in os.listdir(tmpdir):
        if f.startswith('video.'):
            return os.path.join(tmpdir, f)
    raise RuntimeError('ä¸‹è¼‰å¤±æ•—ï¼šæ‰¾ä¸åˆ°å½±ç‰‡æª”')


def yt_download_mp3(url, tmpdir):
    """YouTube â†’ MP3ï¼ˆä¸åˆ†é›¢éŸ³è»Œï¼Œ128kbpsï¼‰"""
    output_path = os.path.join(tmpdir, 'raw.%(ext)s')
    r = subprocess.run(
        ['yt-dlp', '-x', '--audio-format', 'wav',
         '-o', output_path, '--no-playlist', url],
        capture_output=True, text=True, timeout=300)
    if r.returncode != 0:
        raise RuntimeError(f'yt-dlp å¤±æ•—: {r.stderr[-300:]}')
    raw_path = None
    for f in os.listdir(tmpdir):
        if f.startswith('raw.'):
            raw_path = os.path.join(tmpdir, f)
            break
    if not raw_path:
        raise RuntimeError('ä¸‹è¼‰å¤±æ•—ï¼šæ‰¾ä¸åˆ°éŸ³é »æª”')

    mp3_path = os.path.join(tmpdir, 'audio.mp3')
    subprocess.run(
        ['ffmpeg', '-y', '-i', raw_path, '-b:a', '128k', mp3_path],
        capture_output=True, timeout=120)
    if not os.path.exists(mp3_path):
        raise RuntimeError('ffmpeg è½‰æª”å¤±æ•—')
    return mp3_path


GH_REPO = 'rubby0605/music_grab'
GH_RELEASE_TAG = 'mp3-files'


def upload_to_github(filepath, filename):
    """ä¸Šå‚³æª”æ¡ˆåˆ° GitHub Releaseï¼Œå›å‚³ä¸‹è¼‰é€£çµ"""
    gh_token = os.environ.get('GH_TOKEN', '')
    if not gh_token:
        raise RuntimeError('æœªè¨­å®š GH_TOKEN')

    # è¤‡è£½æª”æ¡ˆä¸¦é‡æ–°å‘½å
    upload_path = os.path.join(os.path.dirname(filepath), filename)
    if upload_path != filepath:
        shutil.copy2(filepath, upload_path)

    # ä¸Šå‚³ï¼ˆ--clobber è¦†è“‹åŒåæª”æ¡ˆï¼‰
    r = subprocess.run(
        ['gh', 'release', 'upload', GH_RELEASE_TAG, upload_path,
         '--repo', GH_REPO, '--clobber'],
        capture_output=True, text=True, timeout=300,
        env={**os.environ, 'GH_TOKEN': gh_token})
    if r.returncode != 0:
        raise RuntimeError(f'GitHub ä¸Šå‚³å¤±æ•—: {r.stderr[-200:]}')

    from urllib.parse import quote
    safe_fn = quote(filename)
    return f'https://github.com/{GH_REPO}/releases/download/{GH_RELEASE_TAG}/{safe_fn}'


def transcribe_to_midi(audio_path, output_midi):
    """ç”¨ ByteDance Piano Transcription è½‰ MIDI"""
    print('  Loading audio for transcription...')
    audio, _ = load_audio(audio_path, sr=PT_SR, mono=True)
    print(f'  Audio: {len(audio)/PT_SR:.1f}s')
    print('  Running Piano Transcription model...')
    transcriptor = PianoTranscription(device='cpu')
    transcriptor.transcribe(audio, output_midi)
    print(f'  MIDI saved: {output_midi}')
    return output_midi


def vocals_to_midi_pyin(audio_path, output_midi):
    """ç”¨ librosa pyin å°‡å–®éŸ³äººè²è½‰æˆ MIDIï¼ˆæ¯” Piano Transcription æº–ç¢ºï¼‰"""
    y, sr = librosa.load(audio_path, sr=22050, mono=True)
    f0, voiced_flag, voiced_probs = librosa.pyin(
        y, fmin=librosa.note_to_hz('C2'),
        fmax=librosa.note_to_hz('C6'), sr=sr)
    times = librosa.times_like(f0, sr=sr)

    midi_data = pretty_midi.PrettyMIDI()
    voice = pretty_midi.Instrument(program=0, name='Vocals')

    in_note = False
    note_start = 0.0
    note_pitch = 0

    for i in range(len(f0)):
        if voiced_flag[i] and f0[i] is not None and not np.isnan(f0[i]):
            midi_pitch = int(round(librosa.hz_to_midi(f0[i])))
            midi_pitch = max(21, min(108, midi_pitch))
            if not in_note:
                in_note = True
                note_start = times[i]
                note_pitch = midi_pitch
            elif abs(midi_pitch - note_pitch) > 1:
                dur = times[i] - note_start
                if dur > 0.05:
                    voice.notes.append(pretty_midi.Note(
                        velocity=80, pitch=note_pitch,
                        start=note_start, end=times[i]))
                note_start = times[i]
                note_pitch = midi_pitch
        else:
            if in_note:
                dur = times[i] - note_start
                if dur > 0.05:
                    voice.notes.append(pretty_midi.Note(
                        velocity=80, pitch=note_pitch,
                        start=note_start, end=times[i]))
                in_note = False

    if in_note and len(times) > 0:
        dur = times[-1] - note_start
        if dur > 0.05:
            voice.notes.append(pretty_midi.Note(
                velocity=80, pitch=note_pitch,
                start=note_start, end=times[-1]))

    midi_data.instruments.append(voice)
    midi_data.write(output_midi)
    print(f'  pyin: {len(voice.notes)} vocal notes')
    return output_midi


def midi_pipeline(url, tmpdir):
    """YouTube â†’ demucs â†’ Piano Transcription â†’ MIDI (vocals + other)"""
    title = yt_get_title(url)
    print(f'  Title: {title}')

    # 1. Download
    wav = yt_download_audio(url, tmpdir)

    # 2. Demucs separate
    stems = separate_stems(wav, tmpdir)

    other_path = stems.get('other')
    vocals_path = stems.get('vocals')
    if not other_path:
        raise RuntimeError('demucs æœªç”¢å‡º other è»Œ')

    # 3. Transcribe other (instruments)
    print('  Transcribing instruments...')
    other_midi = os.path.join(tmpdir, 'other.mid')
    transcribe_to_midi(other_path, other_midi)

    # 4. Transcribe vocals (pyin for monophonic)
    vocals_midi = None
    if vocals_path:
        print('  Transcribing vocals (pyin)...')
        vocals_midi = os.path.join(tmpdir, 'vocals.mid')
        vocals_to_midi_pyin(vocals_path, vocals_midi)

    return other_midi, vocals_midi, title


def merge_midi(other_midi, vocals_midi, output_path):
    """åˆä½µäººè²å’Œä¼´å¥ MIDIï¼Œäººè²ç”¨ç¨ç«‹ track"""
    other = pretty_midi.PrettyMIDI(other_midi)

    # é‡æ–°å‘½å other çš„ instrument
    for inst in other.instruments:
        if not inst.is_drum:
            inst.name = 'Piano'

    if vocals_midi:
        vocals = pretty_midi.PrettyMIDI(vocals_midi)
        for inst in vocals.instruments:
            if not inst.is_drum:
                inst.name = 'Vocals'
                inst.program = 73  # Flute (è¿‘ä¼¼äººè²çš„éŸ³è‰²)
                other.instruments.append(inst)

    other.write(output_path)
    return output_path


def pdf_pipeline(url, tmpdir, progress_cb=None):
    """YouTube â†’ demucs â†’ Piano Transcription â†’ Whisper â†’ LilyPond â†’ PDF"""
    def update(msg):
        if progress_cb:
            progress_cb(msg)
        print(f'  {msg}')

    update('â¬‡ï¸ ä¸‹è¼‰éŸ³é »ä¸­...')
    title = yt_get_title(url)
    wav = yt_download_audio(url, tmpdir)

    update('ğŸ›ï¸ Demucs åˆ†é›¢éŸ³è»Œä¸­...')
    stems = separate_stems(wav, tmpdir)

    other_path = stems.get('other')
    vocals_path = stems.get('vocals')

    update('ğŸ¹ è½‰è­œï¼šä¼´å¥è»Œ...')
    other_midi = os.path.join(tmpdir, 'other.mid')
    transcribe_to_midi(other_path, other_midi)

    vocals_midi = None
    if vocals_path:
        update('ğŸ¤ è½‰è­œï¼šäººè²è»Œ (pyin)...')
        vocals_midi = os.path.join(tmpdir, 'vocals.mid')
        vocals_to_midi_pyin(vocals_path, vocals_midi)

    # Whisper è¾¨è­˜æ­Œè©
    whisper_result = None
    if vocals_path:
        update('ğŸ“ Whisper è¾¨è­˜æ­Œè©ä¸­...')
        try:
            whisper_result = whisper_transcribe(vocals_path, tmpdir)
            lyrics_text = whisper_result.text if hasattr(whisper_result, 'text') else ''
            print(f'  Lyrics: {lyrics_text[:80]}...')
        except Exception as e:
            print(f'  Whisper error: {e}')

    # åˆä½µ MIDI
    merged_midi = os.path.join(tmpdir, 'merged.mid')
    merge_midi(other_midi, vocals_midi, merged_midi)

    update('ğŸ“„ ç”¢ç”Ÿæ¨‚è­œ PDF...')
    ly_path = os.path.join(tmpdir, 'score.ly')
    midi_to_lilypond_full(other_midi, vocals_midi, ly_path, title=title,
                          whisper_result=whisper_result, audio_path=other_path)

    pdf_path = lilypond_to_pdf(ly_path, tmpdir)
    update('âœ… å®Œæˆï¼')
    return pdf_path, merged_midi, title


def whisper_transcribe(audio_path, tmpdir):
    """ç”¨ OpenAI Whisper API è¾¨è­˜æ­Œè©ï¼Œå›å‚³ word-level æ™‚é–“æˆ³"""
    openai_client = OpenAI()
    # å£“ç¸®æˆå° mp3 çµ¦ API
    compressed = os.path.join(tmpdir, 'whisper_input.mp3')
    subprocess.run(
        ['ffmpeg', '-y', '-i', audio_path, '-ac', '1', '-ar', '16000', '-b:a', '64k', compressed],
        capture_output=True, timeout=60)
    with open(compressed, 'rb') as f:
        result = openai_client.audio.transcriptions.create(
            model='whisper-1', file=f,
            response_format='verbose_json',
            timestamp_granularities=['word', 'segment'])
    return result


def whisper_to_srt(audio_path, output_srt, tmpdir):
    """éŸ³é » â†’ Whisper â†’ SRT å­—å¹•æª”"""
    result = whisper_transcribe(audio_path, tmpdir)
    segments = result.segments if hasattr(result, 'segments') else []
    with open(output_srt, 'w', encoding='utf-8') as f:
        for i, seg in enumerate(segments):
            start = seg['start'] if isinstance(seg, dict) else seg.start
            end = seg['end'] if isinstance(seg, dict) else seg.end
            text = seg['text'] if isinstance(seg, dict) else seg.text
            f.write(f"{i+1}\n")
            f.write(f"{_srt_time(start)} --> {_srt_time(end)}\n")
            f.write(f"{text.strip()}\n\n")
    return output_srt


def _srt_time(seconds):
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    ms = int((seconds % 1) * 1000)
    return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"


def video_add_subtitles(video_path, srt_path, output_path):
    """æŠŠ SRT å­—å¹•ç‡’é€²å½±ç‰‡"""
    r = subprocess.run(
        ['ffmpeg', '-y', '-i', video_path, '-vf', f"subtitles={srt_path}",
         '-c:a', 'copy', output_path],
        capture_output=True, text=True, timeout=600)
    if r.returncode != 0:
        raise RuntimeError(f'ffmpeg å­—å¹•åˆæˆå¤±æ•—: {r.stderr[-200:]}')
    return output_path


def yt_download_audio(url, tmpdir):
    output_path = os.path.join(tmpdir, 'audio.%(ext)s')
    r = subprocess.run(
        ['yt-dlp', '-x', '--audio-format', 'wav', '--audio-quality', '0',
         '-o', output_path, '--no-playlist', url],
        capture_output=True, text=True, timeout=120)
    if r.returncode != 0:
        raise RuntimeError(f'yt-dlp å¤±æ•—: {r.stderr[-300:]}')
    for f in os.listdir(tmpdir):
        if f.startswith('audio.'):
            return os.path.join(tmpdir, f)
    raise RuntimeError('ä¸‹è¼‰å¤±æ•—ï¼šæ‰¾ä¸åˆ°éŸ³é »æª”')


def separate_stems(wav_path, tmpdir):
    """ç”¨ demucs åˆ†é›¢ 4 è»Œï¼švocals, drums, bass, other"""
    print('  Separating stems with demucs (4 stems)...')
    r = subprocess.run(
        ['python', '-m', 'demucs', '-o', tmpdir, '--mp3', wav_path],
        capture_output=True, text=True, timeout=1200)
    if r.returncode != 0:
        print(f'  demucs warning: {r.stderr[-200:]}')

    base = os.path.splitext(os.path.basename(wav_path))[0]
    stems = {}
    stem_names = ['vocals', 'drums', 'bass', 'other']

    # æ‰¾ demucs è¼¸å‡ºç›®éŒ„
    for model_dir in ['htdemucs', 'htdemucs_ft', 'mdx_extra']:
        stem_dir = os.path.join(tmpdir, model_dir, base)
        if os.path.isdir(stem_dir):
            for name in stem_names:
                for ext in ['.mp3', '.wav']:
                    p = os.path.join(stem_dir, name + ext)
                    if os.path.exists(p):
                        stems[name] = p
                        print(f'    {name}: {os.path.getsize(p)/1024:.0f} KB')
            break

    if not stems:
        raise RuntimeError('demucs æœªç”¢å‡ºåˆ†é›¢éŸ³è»Œ')

    print(f'  åˆ†é›¢å®Œæˆï¼Œå…± {len(stems)} è»Œ')
    return stems


def detect_key(y, sr):
    """ç”¨ chroma + Krumhansl-Kessler åµæ¸¬èª¿æ€§"""
    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
    chroma_avg = chroma.mean(axis=1)

    major_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09,
                              2.52, 5.19, 2.39, 3.66, 2.29, 2.88])
    minor_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53,
                              2.54, 4.75, 3.98, 2.69, 3.34, 3.17])

    NAMES = ['C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']
    best_corr, best_key, best_mode = -2, 0, 'major'

    for shift in range(12):
        rolled = np.roll(chroma_avg, -shift)
        corr_maj = np.corrcoef(rolled, major_profile)[0, 1]
        corr_min = np.corrcoef(rolled, minor_profile)[0, 1]
        if corr_maj > best_corr:
            best_corr, best_key, best_mode = corr_maj, shift, 'major'
        if corr_min > best_corr:
            best_corr, best_key, best_mode = corr_min, shift, 'minor'

    return f'{NAMES[best_key]} {best_mode}'


def detect_bpm(y, sr):
    """åµæ¸¬ BPM"""
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
    if hasattr(tempo, '__len__'):
        tempo = tempo[0]
    return int(round(tempo))


def audio_to_midi(audio_path, tmpdir):
    """ç”¨ librosa CQT + onset detection å¾ä¹¾æ·¨éŸ³è»Œè½‰ MIDI"""
    print('  Loading audio for transcription...')
    y, sr = librosa.load(audio_path, sr=22050, mono=True)

    # åµæ¸¬èª¿æ€§å’Œ BPM
    key_str = detect_key(y, sr)
    bpm = detect_bpm(y, sr)
    print(f'  Key: {key_str}, BPM: {bpm}')

    hop = 512
    # onset detection
    onset_frames = librosa.onset.onset_detect(y=y, sr=sr, hop_length=hop, backtrack=True)
    onset_times = librosa.frames_to_time(onset_frames, sr=sr, hop_length=hop)
    print(f'  åµæ¸¬åˆ° {len(onset_times)} å€‹ onset')

    # CQT é »è­œï¼ˆC1~C8, 84 binsï¼‰
    C = np.abs(librosa.cqt(y, sr=sr, hop_length=hop,
                            fmin=librosa.note_to_hz('C1'), n_bins=84))
    times = librosa.times_like(C, sr=sr, hop_length=hop)

    # å‹•æ…‹é–€æª»
    threshold = np.percentile(C, 92)

    midi_data = pretty_midi.PrettyMIDI(initial_tempo=bpm)
    piano = pretty_midi.Instrument(program=0, name='Piano')

    for idx in range(len(onset_times)):
        t_start = onset_times[idx]
        t_end = onset_times[idx + 1] if idx + 1 < len(onset_times) else times[-1]

        f_start = np.searchsorted(times, t_start)
        f_end = np.searchsorted(times, t_end)
        if f_end <= f_start:
            f_end = f_start + 1
        if f_start >= C.shape[1]:
            continue

        segment = C[:, f_start:min(f_end, C.shape[1])]
        avg_energy = segment.mean(axis=1)

        active_bins = np.where(avg_energy > threshold)[0]
        if len(active_bins) == 0:
            continue

        # æœ€å¤š 6 å€‹åŒæ™‚éŸ³
        if len(active_bins) > 6:
            top_idx = np.argsort(avg_energy[active_bins])[-6:]
            active_bins = active_bins[top_idx]

        for b in active_bins:
            midi_pitch = b + 24  # C1 = MIDI 24
            midi_pitch = max(21, min(108, midi_pitch))
            dur = t_end - t_start
            if dur < 0.03:
                continue
            vel = int(min(127, max(30, 40 + avg_energy[b] / threshold * 40)))
            note = pretty_midi.Note(velocity=vel, pitch=midi_pitch,
                                     start=t_start, end=t_end)
            piano.notes.append(note)

    if not piano.notes:
        raise RuntimeError('ç„¡æ³•åµæ¸¬åˆ°éŸ³ç¬¦')

    midi_data.instruments.append(piano)
    midi_path = os.path.join(tmpdir, 'transcribed.mid')
    midi_data.write(midi_path)
    print(f'  MIDI: {len(piano.notes)} å€‹éŸ³ç¬¦')

    meta = {'key': key_str, 'bpm': bpm}
    return midi_path, meta


def midi_to_lilypond(midi_path, ly_path, title='Piano', key_info=None):
    """MIDI â†’ LilyPond æ¨‚è­œ"""
    midi = pretty_midi.PrettyMIDI(midi_path)
    all_notes = []
    for inst in midi.instruments:
        if not inst.is_drum:
            all_notes.extend(inst.notes)
    if not all_notes:
        raise RuntimeError('MIDI ä¸­æ²’æœ‰éŸ³ç¬¦')

    all_notes.sort(key=lambda n: n.start)

    tempo_times, tempos = midi.get_tempo_changes()
    bpm = int(tempos[0]) if len(tempos) > 0 else 120

    # è§£æèª¿æ€§
    key_str = (key_info or {}).get('key', 'C major')
    use_flats = any(x in key_str for x in ['b ', 'flat', 'Bb', 'Eb', 'Ab', 'Db', 'Gb',
                                             'F major', 'D minor', 'G minor', 'C minor',
                                             'F minor', 'Bb', 'Eb'])

    SHARP_NAMES = ['c', 'cis', 'd', 'dis', 'e', 'f', 'fis', 'g', 'gis', 'a', 'ais', 'b']
    FLAT_NAMES = ['c', 'des', 'd', 'ees', 'e', 'f', 'ges', 'g', 'aes', 'a', 'bes', 'b']
    note_names = FLAT_NAMES if use_flats else SHARP_NAMES

    # LilyPond èª¿å
    KEY_MAP = {
        'C major': 'c \\major', 'G major': 'g \\major', 'D major': 'd \\major',
        'A major': 'a \\major', 'E major': 'e \\major', 'B major': 'b \\major',
        'F major': 'f \\major', 'Bb major': 'bes \\major', 'Eb major': 'ees \\major',
        'Ab major': 'aes \\major', 'Db major': 'des \\major', 'Gb major': 'ges \\major',
        'F# major': 'fis \\major', 'C# major': 'cis \\major',
        'A minor': 'a \\minor', 'E minor': 'e \\minor', 'B minor': 'b \\minor',
        'F# minor': 'fis \\minor', 'C# minor': 'cis \\minor', 'G# minor': 'gis \\minor',
        'D minor': 'd \\minor', 'G minor': 'g \\minor', 'C minor': 'c \\minor',
        'F minor': 'f \\minor', 'Bb minor': 'bes \\minor', 'Eb minor': 'ees \\minor',
    }
    ly_key = KEY_MAP.get(key_str, 'c \\major')

    # æ‹è™Ÿ
    ts = (key_info or {}).get('time_signature', [4, 4])
    time_sig = f'{ts[0]}/{ts[1]}' if isinstance(ts, list) and len(ts) == 2 else '4/4'

    def pitch_to_lily(p):
        octave = (p // 12) - 1
        name = note_names[p % 12]
        diff = octave - 3
        if diff > 0:
            name += "'" * diff
        elif diff < 0:
            name += "," * abs(diff)
        return name

    def dur_to_lily(dur_sec):
        beat = 60.0 / bpm
        beats = dur_sec / beat
        if beats >= 3.5: return '1'
        elif beats >= 1.75: return '2'
        elif beats >= 0.875: return '4'
        elif beats >= 0.4375: return '8'
        elif beats >= 0.21875: return '16'
        else: return '32'

    right = [n for n in all_notes if n.pitch >= 60]
    left = [n for n in all_notes if n.pitch < 60]

    def to_str(nl):
        if not nl: return 'r1 r1 r1 r1'
        return ' '.join(f'{pitch_to_lily(n.pitch)}{dur_to_lily(n.end - n.start)}' for n in nl)

    safe_title = re.sub(r'[\\\"{}]', '', title)
    ly = f'''\\version "2.24.0"
\\header {{
  title = "{safe_title}"
  subtitle = "AI-transcribed from YouTube â€” {key_str}"
  tagline = "Generated by Discord Sheet Music Bot"
}}
\\score {{
  \\new PianoStaff <<
    \\new Staff = "right" {{
      \\clef treble
      \\key {ly_key}
      \\time {time_sig}
      \\tempo 4 = {bpm}
      {{ {to_str(right)} }}
    }}
    \\new Staff = "left" {{
      \\clef bass
      \\key {ly_key}
      \\time {time_sig}
      {{ {to_str(left)} }}
    }}
  >>
  \\layout {{ }}
}}
'''
    with open(ly_path, 'w') as f:
        f.write(ly)


def align_lyrics_to_notes(whisper_result, vocal_notes):
    """ç”¨ Whisper æ™‚é–“æˆ³æŠŠæ­Œè©å°é½Šåˆ°äººè²éŸ³ç¬¦ï¼ˆå…©æŒ‡é‡æƒæï¼‰"""
    if not whisper_result or not vocal_notes:
        return []

    segments = []
    raw_segments = getattr(whisper_result, 'segments', [])
    for seg in raw_segments:
        if isinstance(seg, dict):
            segments.append((seg['start'], seg['end'], seg['text'].strip()))
        else:
            segments.append((seg.start, seg.end, seg.text.strip()))

    if not segments:
        return []

    # æŠŠæ¯å€‹ segment çš„æ–‡å­—æ‹†æˆå¸¶æ™‚é–“æˆ³çš„å­—å…ƒ
    timed_chars = []
    for seg_start, seg_end, text in segments:
        chars = [ch for ch in text if ch.strip()]
        if not chars:
            continue
        char_dur = (seg_end - seg_start) / max(len(chars), 1)
        for i, ch in enumerate(chars):
            timed_chars.append((seg_start + i * char_dur, ch))

    if not timed_chars:
        return []

    # å…©æŒ‡é‡å°é½Šï¼šæ¯å€‹éŸ³ç¬¦æ‰¾æœ€è¿‘çš„æœªä½¿ç”¨å­—å…ƒ
    result = []
    ci = 0
    for note in vocal_notes:
        # è·³éæ™‚é–“ä¸Šå¤ªæ—©çš„å­—å…ƒ
        while ci < len(timed_chars) and timed_chars[ci][0] < note.start - 0.8:
            ci += 1

        if ci < len(timed_chars) and abs(timed_chars[ci][0] - note.start) < 1.5:
            ch = timed_chars[ci][1]
            safe_ch = ch.replace('"', '').replace('\\', '').replace('{', '').replace('}', '')
            result.append(f'"{safe_ch}"' if safe_ch else '_')
            ci += 1
        else:
            result.append('_')

    return result


def midi_to_lilypond_full(other_midi, vocals_midi, ly_path, title='Score',
                          whisper_result=None, audio_path=None):
    """MIDI â†’ LilyPond ç¸½è­œï¼ˆäººè²+æ­Œè© + é‹¼ç´å·¦å³æ‰‹ï¼Œå«å’Œå¼¦+ä¼‘æ­¢ç¬¦+èª¿æ€§ï¼‰"""

    def get_notes(midi_path):
        midi = pretty_midi.PrettyMIDI(midi_path)
        notes = []
        for inst in midi.instruments:
            if not inst.is_drum:
                notes.extend(inst.notes)
        notes.sort(key=lambda n: (n.start, n.pitch))
        return notes, midi

    other_notes, other_pm = get_notes(other_midi)

    tempo_times, tempos = other_pm.get_tempo_changes()
    bpm = int(tempos[0]) if len(tempos) > 0 else 120
    beat_sec = 60.0 / bpm

    # èª¿æ€§åµæ¸¬
    key_str = 'C major'
    if audio_path:
        try:
            y_key, sr_key = librosa.load(audio_path, sr=22050, mono=True)
            key_str = detect_key(y_key, sr_key)
            print(f'  Detected key: {key_str}')
        except Exception as e:
            print(f'  Key detection failed: {e}')

    FLAT_KEYS = {'F major', 'Bb major', 'Eb major', 'Ab major', 'Db major', 'Gb major',
                 'D minor', 'G minor', 'C minor', 'F minor', 'Bb minor', 'Eb minor'}
    use_flats = key_str in FLAT_KEYS

    SHARP_NAMES = ['c', 'cis', 'd', 'dis', 'e', 'f', 'fis', 'g', 'gis', 'a', 'ais', 'b']
    FLAT_NAMES = ['c', 'des', 'd', 'ees', 'e', 'f', 'ges', 'g', 'aes', 'a', 'bes', 'b']
    note_names = FLAT_NAMES if use_flats else SHARP_NAMES

    KEY_MAP = {
        'C major': 'c \\major', 'G major': 'g \\major', 'D major': 'd \\major',
        'A major': 'a \\major', 'E major': 'e \\major', 'B major': 'b \\major',
        'F major': 'f \\major', 'Bb major': 'bes \\major', 'Eb major': 'ees \\major',
        'Ab major': 'aes \\major', 'Db major': 'des \\major', 'Gb major': 'ges \\major',
        'F# major': 'fis \\major', 'C# major': 'cis \\major',
        'A minor': 'a \\minor', 'E minor': 'e \\minor', 'B minor': 'b \\minor',
        'F# minor': 'fis \\minor', 'C# minor': 'cis \\minor', 'G# minor': 'gis \\minor',
        'D minor': 'd \\minor', 'G minor': 'g \\minor', 'C minor': 'c \\minor',
        'F minor': 'f \\minor', 'Bb minor': 'bes \\minor', 'Eb minor': 'ees \\minor',
    }
    ly_key = KEY_MAP.get(key_str, 'c \\major')

    def pitch_to_lily(p):
        octave = (p // 12) - 1
        name = note_names[p % 12]
        diff = octave - 3
        if diff > 0:
            name += "'" * diff
        elif diff < 0:
            name += "," * abs(diff)
        return name

    def beats_to_lily_dur(beats):
        if beats >= 3.5: return '1'
        elif beats >= 1.75: return '2'
        elif beats >= 1.2: return '4.'
        elif beats >= 0.875: return '4'
        elif beats >= 0.625: return '8.'
        elif beats >= 0.4375: return '8'
        elif beats >= 0.21875: return '16'
        else: return '32'

    def fill_rests(beats):
        if beats <= 0.1:
            return ''
        parts = []
        remaining = beats
        for val, name in [(4.0, 'r1'), (2.0, 'r2'), (1.0, 'r4'), (0.5, 'r8'), (0.25, 'r16')]:
            while remaining >= val - 0.05:
                parts.append(name)
                remaining -= val
        return ' '.join(parts)

    def notes_to_str(note_list):
        """éŸ³ç¬¦åˆ—è¡¨ â†’ LilyPond å­—ä¸²ï¼ˆå«å’Œå¼¦åˆ†çµ„+ä¼‘æ­¢ç¬¦+å°ç¯€ç·šï¼‰"""
        if not note_list:
            return 'R1*4'

        # æŒ‰èµ·å§‹æ™‚é–“åˆ†çµ„ï¼ˆåŒæ™‚é–“çš„éŸ³çµ„æˆå’Œå¼¦ï¼‰
        CHORD_TOL = 0.05  # ç§’
        sorted_notes = sorted(note_list, key=lambda n: (n.start, n.pitch))
        groups = []
        i = 0
        while i < len(sorted_notes):
            group = [sorted_notes[i]]
            j = i + 1
            while j < len(sorted_notes) and abs(sorted_notes[j].start - sorted_notes[i].start) < CHORD_TOL:
                group.append(sorted_notes[j])
                j += 1
            groups.append(group)
            i = j

        bar_dur = 4 * beat_sec  # ä¸€å°ç¯€çš„ç§’æ•¸
        next_bar = bar_dur      # ä¸‹ä¸€å€‹å°ç¯€ç·šçš„æ™‚é–“
        parts = ['\\cadenzaOn']
        cursor = 0.0

        for group in groups:
            gap = group[0].start - cursor
            if gap > beat_sec * 0.2:
                gap_beats = gap / beat_sec
                rest = fill_rests(gap_beats)
                if rest:
                    parts.append(rest)

            min_dur = min(n.end - n.start for n in group)
            dur_beats = min_dur / beat_sec
            dur_str = beats_to_lily_dur(dur_beats)

            if len(group) == 1:
                parts.append(f'{pitch_to_lily(group[0].pitch)}{dur_str}')
            else:
                pitches = ' '.join(pitch_to_lily(n.pitch)
                                   for n in sorted(group, key=lambda n: n.pitch))
                parts.append(f'<{pitches}>{dur_str}')

            cursor = max(n.end for n in group)

            # æ¯éš”ä¸€å°ç¯€æ’å…¥å°ç¯€ç·šï¼ˆè®“ LilyPond æ›è¡Œï¼‰
            while cursor >= next_bar - 0.05:
                parts.append('\\bar "|"')
                next_bar += bar_dur

        parts.append('\\bar "|."')
        return ' '.join(parts)

    # ç”¨ä¸­å¤® C (MIDI 60) åˆ†å·¦å³æ‰‹
    right = [n for n in other_notes if n.pitch >= 60]
    left = [n for n in other_notes if n.pitch < 60]

    # Vocals
    vocal_notes = []
    if vocals_midi:
        vocal_notes, _ = get_notes(vocals_midi)

    # æ­Œè©ï¼ˆç”¨ Whisper æ™‚é–“æˆ³å°é½Šï¼‰
    lyrics_block = ''
    if whisper_result and vocal_notes:
        ly_words = align_lyrics_to_notes(whisper_result, vocal_notes)
        # å»æ‰å°¾éƒ¨é€£çºŒçš„ _
        while ly_words and ly_words[-1] == '_':
            ly_words.pop()
        if ly_words:
            lyrics_block = '\\new Lyrics \\lyricsto "vox" { ' + ' '.join(ly_words) + ' }'

    safe_title = re.sub(r'[\\\"{}]', '', title)
    ly = f'''\\version "2.24.0"
\\header {{
  title = "{safe_title}"
  subtitle = "AI-transcribed from YouTube â€” {key_str}"
  tagline = "Generated by Music Grab Bot"
}}
\\paper {{
  #(set-paper-size "a4")
  top-margin = 10
  bottom-margin = 10
  left-margin = 12
  right-margin = 12
}}
\\score {{
  <<
    \\new Staff = "vocals" \\with {{ instrumentName = "Vocals" }} {{
      \\clef treble
      \\key {ly_key}
      \\time 4/4
      \\tempo 4 = {bpm}
      \\new Voice = "vox" {{ {notes_to_str(vocal_notes)} }}
    }}
    {lyrics_block}
    \\new PianoStaff \\with {{ instrumentName = "Piano" }} <<
      \\new Staff = "right" {{
        \\clef treble
        \\key {ly_key}
        \\time 4/4
        {{ {notes_to_str(right)} }}
      }}
      \\new Staff = "left" {{
        \\clef bass
        \\key {ly_key}
        \\time 4/4
        {{ {notes_to_str(left)} }}
      }}
    >>
  >>
  \\layout {{
    indent = 15\\mm
    short-indent = 5\\mm
  }}
}}
'''
    with open(ly_path, 'w') as f:
        f.write(ly)
    n_lyrics = len(getattr(whisper_result, 'text', '')) if whisper_result else 0
    print(f'  LilyPond: vocals={len(vocal_notes)}, RH={len(right)}, LH={len(left)}, lyrics={n_lyrics} chars')


def lilypond_to_pdf(ly_path, tmpdir):
    r = subprocess.run(
        ['lilypond', '-dno-point-and-click', '-o', os.path.join(tmpdir, 'score'), ly_path],
        capture_output=True, text=True, timeout=600)
    pdf_path = os.path.join(tmpdir, 'score.pdf')
    if not os.path.exists(pdf_path):
        raise RuntimeError(f'LilyPond ç·¨è­¯å¤±æ•—: {r.stderr[-500:]}')
    return pdf_path


def sheet_pipeline(url, tmpdir):
    title = yt_get_title(url)
    print(f'  Title: {title}')

    # 1. YouTube â†’ WAV
    wav = yt_download_audio(url, tmpdir)
    print(f'  Audio: {wav}')

    # 2. demucs åˆ†é›¢ 4 è»Œ
    stems = separate_stems(wav, tmpdir)

    return stems, title


# â”€â”€ Discord Events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@client.event
async def on_ready():
    print(f'Bot å·²ä¸Šç·š: {client.user}')
    print('  åŠŸèƒ½: PDF/DOCXâ†’èªéŸ³, YouTubeâ†’æ¨‚è­œ')


@client.event
async def on_message(message):
    if message.author == client.user or message.author.bot:
        return

    content = message.content.strip()
    loop = asyncio.get_event_loop()
    print(f'  [MSG] {message.author}: {content[:80]}')

    # â”€â”€ !pdf â†’ demucs + Piano Transcription + LilyPond â”€â”€
    # â”€â”€ !help â†’ åŠŸèƒ½èªªæ˜ â”€â”€
    if content.lower() in ('!help', '!æŒ‡ä»¤', '!commands'):
        help_text = """**ğŸµ Music Grab Bot æŒ‡ä»¤èªªæ˜**

ğŸ“¥ **ä¸‹è¼‰**
`YouTube URL` â†’ ç›´æ¥ä¸‹è¼‰ MP3
`!video <URL>` â†’ ä¸‹è¼‰å½±ç‰‡ MP4

ğŸ¼ **éŸ³æ¨‚è™•ç†**
`!dep <URL>` â†’ Demucs åˆ†é›¢å››è»Œï¼ˆäººè²/é¼“/è²æ–¯/å…¶ä»–ï¼‰
`!midi <URL>` â†’ è½‰ MIDIï¼ˆäººè²+ä¼´å¥ï¼‰
`!pdf <URL>` â†’ è½‰æ¨‚è­œ PDFï¼ˆå«æ­Œè©ï¼‰

ğŸ“ **å­—å¹•**
ä¸Šå‚³ MP4/MKV/AVI â†’ Whisper è‡ªå‹•è¾¨è­˜ â†’ SRT å­—å¹•æª”

ğŸ”Š **æ–‡ä»¶è½‰èªéŸ³**
ä¸Šå‚³ PDF æˆ– DOCX â†’ AI æ‘˜è¦ â†’ MP3 èªéŸ³

ğŸ’¡ æ‰€æœ‰ YouTube æŒ‡ä»¤æ”¯æ´ youtube.com å’Œ youtu.be é€£çµ"""
        await message.channel.send(help_text)
        return

    # â”€â”€ æŒ‡ä»¤åˆ¤æ–· â”€â”€
    is_video_cmd = content.lower().startswith('!video')
    is_dep_cmd = content.lower().startswith('!dep')
    is_pdf_cmd = content.lower().startswith('!pdf')
    is_midi_cmd = content.lower().startswith('!midi')
    yt_match = YT_URL_PATTERN.search(content)

    if is_video_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        await message.channel.send('ä¸‹è¼‰å½±ç‰‡ä¸­...')
        tmpdir = tempfile.mkdtemp()
        try:
            title = await loop.run_in_executor(None, yt_get_title, url)
            video_path = await loop.run_in_executor(None, yt_download_video, url, tmpdir)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'video'

            fsize = os.path.getsize(video_path)
            print(f'  Video: {fsize/1024/1024:.1f} MB')
            if fsize <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'**{title}**',
                    file=discord.File(video_path, filename=f'{safe_name}.mp4'))
            else:
                await message.channel.send(f'å½±ç‰‡ {fsize/1024/1024:.1f} MBï¼Œä¸Šå‚³åˆ° GitHub...')
                import time
                ts_name = f'video_{int(time.time())}.mp4'
                dl_url = await loop.run_in_executor(
                    None, upload_to_github, video_path, ts_name)
                await message.channel.send(f'**{title}**\n{dl_url}')
        except Exception as e:
            await message.channel.send(f'ä¸‹è¼‰å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    if is_pdf_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        progress_msg = await message.channel.send('ğŸµ é–‹å§‹è½‰æ¨‚è­œ...')
        tmpdir = tempfile.mkdtemp()
        try:
            # ç”¨ progress callback æ›´æ–° Discord è¨Šæ¯
            progress_state = {'msg': progress_msg, 'loop': loop}

            def _update_progress(text):
                asyncio.run_coroutine_threadsafe(
                    progress_state['msg'].edit(content=text),
                    progress_state['loop'])

            pdf_path, midi_path, title = await loop.run_in_executor(
                None, pdf_pipeline, url, tmpdir, _update_progress)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'score'
            await message.channel.send(
                content=f'**{title}** æ¨‚è­œï¼š',
                file=discord.File(pdf_path, filename=f'{safe_name}.pdf'))
            await message.channel.send(
                content=f'MIDIï¼š',
                file=discord.File(midi_path, filename=f'{safe_name}.mid'))
        except Exception as e:
            await message.channel.send(f'è½‰è­œå¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    if is_midi_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        await message.channel.send('é–‹å§‹è½‰ MIDIï¼ˆä¸‹è¼‰ â†’ åˆ†é›¢éŸ³è»Œ â†’ è½‰è­œï¼‰ï¼Œéœ€è¦å¹¾åˆ†é˜...')
        tmpdir = tempfile.mkdtemp()
        try:
            other_midi, vocals_midi, title = await loop.run_in_executor(
                None, midi_pipeline, url, tmpdir)
            merged = os.path.join(tmpdir, 'merged.mid')
            merge_midi(other_midi, vocals_midi, merged)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'midi'
            await message.channel.send(
                content=f'**{title}** MIDIï¼ˆäººè²+ä¼´å¥ï¼‰ï¼š',
                file=discord.File(merged, filename=f'{safe_name}.mid'))
        except Exception as e:
            await message.channel.send(f'è½‰è­œå¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    # â”€â”€ !dep â†’ demucs åˆ†é›¢å››è»Œ â”€â”€
    if is_dep_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        await message.channel.send('æ”¶åˆ° YouTube é€£çµï¼Œé–‹å§‹åˆ†é›¢éŸ³è»Œï¼ˆéœ€è¦å¹¾åˆ†é˜ï¼‰...')
        tmpdir = tempfile.mkdtemp()
        try:
            stems, title = await loop.run_in_executor(
                None, sheet_pipeline, url, tmpdir)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'audio'

            stem_labels = {
                'vocals': 'ğŸ¤ äººè²', 'drums': 'ğŸ¥ é¼“',
                'bass': 'ğŸ¸ è²æ–¯', 'other': 'ğŸ¹ å…¶ä»–æ¨‚å™¨'
            }
            for stem_name, stem_path in stems.items():
                label = stem_labels.get(stem_name, stem_name)
                await message.channel.send(
                    content=f'**{title}** â€” {label}ï¼š',
                    file=discord.File(stem_path, filename=f'{safe_name}_{stem_name}.mp3'))
            await message.channel.send('åˆ†é›¢å®Œæˆï¼')
        except Exception as e:
            await message.channel.send(f'åˆ†é›¢å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    # â”€â”€ ç›´æ¥è²¼ URL â†’ ä¸‹è¼‰ MP3 â”€â”€
    if yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        await message.channel.send('ä¸‹è¼‰ MP3 ä¸­...')
        tmpdir = tempfile.mkdtemp()
        try:
            title = await loop.run_in_executor(None, yt_get_title, url)
            mp3_path = await loop.run_in_executor(None, yt_download_mp3, url, tmpdir)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'audio'
            filename = f'{safe_name}.mp3'

            fsize = os.path.getsize(mp3_path)
            print(f'  MP3: {fsize/1024/1024:.1f} MB')
            if fsize <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'**{title}**',
                    file=discord.File(mp3_path, filename=filename))
            else:
                await message.channel.send(f'æª”æ¡ˆ {fsize/1024/1024:.1f} MBï¼Œä¸Šå‚³åˆ° GitHub...')
                import time
                ts_name = f'mp3_{int(time.time())}.mp3'
                dl_url = await loop.run_in_executor(
                    None, upload_to_github, mp3_path, ts_name)
                await message.channel.send(f'**{title}**\n{dl_url}')
        except Exception as e:
            await message.channel.send(f'ä¸‹è¼‰å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    # â”€â”€ ä¸Šå‚³ MP4 â†’ Whisper å­—å¹• â”€â”€
    for attachment in message.attachments:
        ext = os.path.splitext(attachment.filename)[1].lower()
        if ext not in VIDEO_EXT:
            continue

        progress_msg = await message.channel.send(f'æ”¶åˆ° `{attachment.filename}`ï¼ŒWhisper å­—å¹•ç”¢ç”Ÿä¸­...')
        tmpdir = tempfile.mkdtemp()
        video_path = os.path.join(tmpdir, attachment.filename)
        await attachment.save(video_path)

        try:
            # æå–éŸ³é »
            audio_path = os.path.join(tmpdir, 'audio.wav')
            await loop.run_in_executor(None, lambda: subprocess.run(
                ['ffmpeg', '-y', '-i', video_path, '-vn', '-ac', '1', '-ar', '16000', audio_path],
                capture_output=True, timeout=120))

            # Whisper
            srt_path = os.path.join(tmpdir, 'subtitles.srt')
            await loop.run_in_executor(None, whisper_to_srt, audio_path, srt_path, tmpdir)

            base_name = os.path.splitext(attachment.filename)[0]
            await message.channel.send(
                content=f'`{attachment.filename}` å­—å¹•ï¼š',
                file=discord.File(srt_path, filename=f'{base_name}.srt'))

            await progress_msg.edit(content='âœ… å­—å¹•ç”¢ç”Ÿå®Œæˆï¼')
        except Exception as e:
            await message.channel.send(f'å­—å¹•å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    # â”€â”€ PDF/DOCX â†’ èªéŸ³ â”€â”€
    for attachment in message.attachments:
        ext = os.path.splitext(attachment.filename)[1].lower()
        if ext not in SUPPORTED_EXT:
            continue

        await message.channel.send(f'æ”¶åˆ° `{attachment.filename}`ï¼Œæ­£åœ¨è™•ç†ä¸­...')
        tmpdir = tempfile.mkdtemp()
        input_path = os.path.join(tmpdir, attachment.filename)
        await attachment.save(input_path)

        try:
            if ext == '.docx':
                text = await loop.run_in_executor(None, read_docx, input_path)
            else:
                text = await loop.run_in_executor(None, read_pdf, input_path)

            if not text.strip():
                await message.channel.send('æå–ä¸åˆ°æ–‡å­—ï¼ˆå¯èƒ½æ˜¯æƒææª”ï¼‰ã€‚')
                continue

            await message.channel.send('AI æ­£åœ¨æ¶ˆåŒ–æ–‡ä»¶å…§å®¹...')
            summary = await loop.run_in_executor(None, summarize_text, text)

            chunks = chunk_text(summary)
            base_name = os.path.splitext(attachment.filename)[0]
            await message.channel.send(f'æ‘˜è¦å®Œæˆï¼ˆ{len(summary)} å­—ï¼‰ï¼Œè½‰æ›èªéŸ³ä¸­...')

            merged_path, part_paths = await loop.run_in_executor(
                None, functools.partial(convert_all_chunks, chunks, tmpdir))

            merged_size = os.path.getsize(merged_path)
            if merged_size <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'`{attachment.filename}` çš„èªéŸ³æ‘˜è¦ï¼š',
                    file=discord.File(merged_path, filename=f'{base_name}.mp3'))
            else:
                await message.channel.send(f'åˆä½µæª”å¤ªå¤§ï¼Œåˆ†æ®µä¸Šå‚³...')
                for i, pp in enumerate(part_paths):
                    await message.channel.send(
                        content=f'èªéŸ³ ({i+1}/{len(part_paths)})',
                        file=discord.File(pp, filename=f'{base_name}_part{i+1}.mp3'))

            await message.channel.send('è½‰æ›å®Œæˆï¼')

        except Exception as e:
            await message.channel.send(f'è½‰æ›å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)


if __name__ == '__main__':
    if not DISCORD_TOKEN:
        print('è«‹è¨­å®šç’°å¢ƒè®Šæ•¸ DISCORD_BOT_TOKEN')
        exit(1)
    client.run(DISCORD_TOKEN)
