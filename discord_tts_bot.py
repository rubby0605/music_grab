#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Discord Botï¼š
  1. ä¸Šå‚³ PDF/DOCX â†’ AI æ‘˜è¦ â†’ MP3 èªéŸ³
  2. è²¼ YouTube URL â†’ é‹¼ç´æ¨‚è­œ PDF + MIDI
"""

import os
import re
import time
import tempfile
import asyncio
import functools
import shutil
import subprocess
import discord
from openai import OpenAI
from newslib import read_docx, read_pdf, chunk_text
import pretty_midi
import numpy as np
import librosa
from piano_transcription_inference import PianoTranscription, sample_rate as PT_SR, load_audio

DISCORD_TOKEN = os.environ.get('DISCORD_BOT_TOKEN', '')
SUPPORTED_EXT = ('.pdf', '.docx')
VIDEO_EXT = ('.mp4', '.mkv', '.avi', '.mov', '.webm')
DISCORD_MAX_BYTES = 8 * 1024 * 1024  # æœªåŠ æˆä¼ºæœå™¨ä¸Šé™ 8MB
YT_URL_PATTERN = re.compile(
    r'(https?://)?(www\.)?(youtube\.com/watch\?v=|youtu\.be/|youtube\.com/shorts/)[\w\-]+'
)

intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)


# â”€â”€ TTS åŠŸèƒ½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def summarize_text(text):
    openai_client = OpenAI()
    max_input = 12000
    system_msg = (
        'ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡ä»¶æ‘˜è¦åŠ©ç†ã€‚'
        'è«‹å°‡ä»¥ä¸‹æ–‡ä»¶å…§å®¹æ¶ˆåŒ–æ•´ç†æˆé©åˆèªéŸ³æ’­å ±çš„æ–‡ç¨¿ã€‚'
        'è¦æ±‚ï¼šä¿ç•™é‡è¦è³‡è¨Šå’Œé—œéµæ•¸æ“šã€å»é™¤æ ¼å¼é›œè¨Šã€å£èªåŒ–ã€ç¹é«”ä¸­æ–‡ã€ä¸åŠ å‰è¨€ã€‚'
    )
    if len(text) > max_input:
        segments = [text[i:i+max_input] for i in range(0, len(text), max_input)]
        summaries = []
        for i, seg in enumerate(segments):
            resp = openai_client.chat.completions.create(
                model='gpt-4o-mini', temperature=0.3,
                messages=[
                    {'role': 'system', 'content': system_msg},
                    {'role': 'user', 'content': f'ç¬¬ {i+1}/{len(segments)} éƒ¨åˆ†ï¼š\n\n{seg}'}
                ])
            summaries.append(resp.choices[0].message.content)
        return '\n\n'.join(summaries)
    else:
        resp = openai_client.chat.completions.create(
            model='gpt-4o-mini', temperature=0.3,
            messages=[{'role': 'system', 'content': system_msg}, {'role': 'user', 'content': text}])
        return resp.choices[0].message.content


def tts_single_chunk(text, output_path, voice='alloy', model='tts-1'):
    openai_client = OpenAI()
    response = openai_client.audio.speech.create(model=model, voice=voice, input=text)
    response.stream_to_file(output_path)


def convert_all_chunks(chunks, tmpdir, voice='alloy', model='tts-1'):
    part_paths = []
    for i, chunk in enumerate(chunks):
        part_path = os.path.join(tmpdir, f'part_{i}.mp3')
        tts_single_chunk(chunk, part_path, voice=voice, model=model)
        part_paths.append(part_path)
    merged_path = os.path.join(tmpdir, 'merged.mp3')
    with open(merged_path, 'wb') as out:
        for p in part_paths:
            with open(p, 'rb') as f:
                out.write(f.read())
    return merged_path, part_paths


# â”€â”€ æ¨‚è­œåŠŸèƒ½ï¼ˆOpenAI GPT-4o Audioï¼‰â”€â”€â”€â”€â”€â”€â”€â”€

def yt_get_title(url):
    try:
        r = subprocess.run(['yt-dlp', '--get-title', '--no-playlist', url],
                           capture_output=True, text=True, timeout=30)
        return r.stdout.strip()[:60] or 'Untitled'
    except Exception:
        return 'Untitled'


def yt_download_video(url, tmpdir):
    """YouTube â†’ MP4 å½±ç‰‡"""
    output_path = os.path.join(tmpdir, 'video.%(ext)s')
    r = subprocess.run(
        ['yt-dlp', '-f', 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
         '--merge-output-format', 'mp4',
         '-o', output_path, '--no-playlist', url],
        capture_output=True, text=True, timeout=600)
    if r.returncode != 0:
        raise RuntimeError(f'yt-dlp å¤±æ•—: {r.stderr[-300:]}')
    for f in os.listdir(tmpdir):
        if f.startswith('video.'):
            return os.path.join(tmpdir, f)
    raise RuntimeError('ä¸‹è¼‰å¤±æ•—ï¼šæ‰¾ä¸åˆ°å½±ç‰‡æª”')


def yt_download_mp3(url, tmpdir):
    """YouTube â†’ MP3ï¼ˆä¸åˆ†é›¢éŸ³è»Œï¼Œ128kbpsï¼‰"""
    output_path = os.path.join(tmpdir, 'raw.%(ext)s')
    r = subprocess.run(
        ['yt-dlp', '-x', '--audio-format', 'wav',
         '-o', output_path, '--no-playlist', url],
        capture_output=True, text=True, timeout=300)
    if r.returncode != 0:
        raise RuntimeError(f'yt-dlp å¤±æ•—: {r.stderr[-300:]}')
    raw_path = None
    for f in os.listdir(tmpdir):
        if f.startswith('raw.'):
            raw_path = os.path.join(tmpdir, f)
            break
    if not raw_path:
        raise RuntimeError('ä¸‹è¼‰å¤±æ•—ï¼šæ‰¾ä¸åˆ°éŸ³é »æª”')

    mp3_path = os.path.join(tmpdir, 'audio.mp3')
    subprocess.run(
        ['ffmpeg', '-y', '-i', raw_path, '-b:a', '128k', mp3_path],
        capture_output=True, timeout=120)
    if not os.path.exists(mp3_path):
        raise RuntimeError('ffmpeg è½‰æª”å¤±æ•—')
    return mp3_path


GH_REPO = 'rubby0605/music_grab'
GH_RELEASE_TAG = 'mp3-files'


def upload_to_github(filepath, filename):
    """ä¸Šå‚³æª”æ¡ˆåˆ° GitHub Releaseï¼Œå›å‚³ä¸‹è¼‰é€£çµ"""
    gh_token = os.environ.get('GH_TOKEN', '')
    if not gh_token:
        raise RuntimeError('æœªè¨­å®š GH_TOKEN')

    # è¤‡è£½æª”æ¡ˆä¸¦é‡æ–°å‘½å
    upload_path = os.path.join(os.path.dirname(filepath), filename)
    if upload_path != filepath:
        shutil.copy2(filepath, upload_path)

    # ä¸Šå‚³ï¼ˆ--clobber è¦†è“‹åŒåæª”æ¡ˆï¼‰
    r = subprocess.run(
        ['gh', 'release', 'upload', GH_RELEASE_TAG, upload_path,
         '--repo', GH_REPO, '--clobber'],
        capture_output=True, text=True, timeout=300,
        env={**os.environ, 'GH_TOKEN': gh_token})
    if r.returncode != 0:
        raise RuntimeError(f'GitHub ä¸Šå‚³å¤±æ•—: {r.stderr[-200:]}')

    from urllib.parse import quote
    safe_fn = quote(filename)
    return f'https://github.com/{GH_REPO}/releases/download/{GH_RELEASE_TAG}/{safe_fn}'


def transcribe_to_midi(audio_path, output_midi):
    """ç”¨ ByteDance Piano Transcription è½‰ MIDI"""
    print('  Loading audio for transcription...')
    audio, _ = load_audio(audio_path, sr=PT_SR, mono=True)
    print(f'  Audio: {len(audio)/PT_SR:.1f}s')
    print('  Running Piano Transcription model...')
    transcriptor = PianoTranscription(device='cpu')
    transcriptor.transcribe(audio, output_midi)
    print(f'  MIDI saved: {output_midi}')
    return output_midi


def vocals_to_midi_pyin(audio_path, output_midi):
    """ç”¨ librosa pyin å°‡å–®éŸ³äººè²è½‰æˆ MIDIï¼ˆæ¯” Piano Transcription æº–ç¢ºï¼‰"""
    y, sr = librosa.load(audio_path, sr=22050, mono=True)
    f0, voiced_flag, voiced_probs = librosa.pyin(
        y, fmin=librosa.note_to_hz('C2'),
        fmax=librosa.note_to_hz('C6'), sr=sr)
    times = librosa.times_like(f0, sr=sr)

    midi_data = pretty_midi.PrettyMIDI()
    voice = pretty_midi.Instrument(program=0, name='Vocals')

    in_note = False
    note_start = 0.0
    note_pitch = 0

    for i in range(len(f0)):
        if voiced_flag[i] and f0[i] is not None and not np.isnan(f0[i]):
            midi_pitch = int(round(librosa.hz_to_midi(f0[i])))
            midi_pitch = max(21, min(108, midi_pitch))
            if not in_note:
                in_note = True
                note_start = times[i]
                note_pitch = midi_pitch
            elif abs(midi_pitch - note_pitch) > 1:
                dur = times[i] - note_start
                if dur > 0.05:
                    voice.notes.append(pretty_midi.Note(
                        velocity=80, pitch=note_pitch,
                        start=note_start, end=times[i]))
                note_start = times[i]
                note_pitch = midi_pitch
        else:
            if in_note:
                dur = times[i] - note_start
                if dur > 0.05:
                    voice.notes.append(pretty_midi.Note(
                        velocity=80, pitch=note_pitch,
                        start=note_start, end=times[i]))
                in_note = False

    if in_note and len(times) > 0:
        dur = times[-1] - note_start
        if dur > 0.05:
            voice.notes.append(pretty_midi.Note(
                velocity=80, pitch=note_pitch,
                start=note_start, end=times[-1]))

    midi_data.instruments.append(voice)
    midi_data.write(output_midi)
    print(f'  pyin: {len(voice.notes)} vocal notes')
    return output_midi


def midi_pipeline(url, tmpdir):
    """YouTube â†’ demucs â†’ Piano Transcription â†’ MIDI (vocals + other)"""
    title = yt_get_title(url)
    print(f'  Title: {title}')

    # 1. Download
    wav = yt_download_audio(url, tmpdir)

    # 2. Demucs separate
    stems = separate_stems(wav, tmpdir)

    other_path = stems.get('other')
    vocals_path = stems.get('vocals')
    if not other_path:
        raise RuntimeError('demucs æœªç”¢å‡º other è»Œ')

    # 3. Transcribe other (instruments)
    print('  Transcribing instruments...')
    other_midi = os.path.join(tmpdir, 'other.mid')
    transcribe_to_midi(other_path, other_midi)

    # 4. Transcribe vocals (pyin for monophonic)
    vocals_midi = None
    if vocals_path:
        print('  Transcribing vocals (pyin)...')
        vocals_midi = os.path.join(tmpdir, 'vocals.mid')
        vocals_to_midi_pyin(vocals_path, vocals_midi)

    return other_midi, vocals_midi, title


def merge_midi(other_midi, vocals_midi, output_path):
    """åˆä½µäººè²å’Œä¼´å¥ MIDIï¼Œäººè²ç”¨ç¨ç«‹ track"""
    other = pretty_midi.PrettyMIDI(other_midi)

    # é‡æ–°å‘½å other çš„ instrument
    for inst in other.instruments:
        if not inst.is_drum:
            inst.name = 'Piano'

    if vocals_midi:
        vocals = pretty_midi.PrettyMIDI(vocals_midi)
        for inst in vocals.instruments:
            if not inst.is_drum:
                inst.name = 'Vocals'
                inst.program = 73  # Flute (è¿‘ä¼¼äººè²çš„éŸ³è‰²)
                other.instruments.append(inst)

    other.write(output_path)
    return output_path


def pdf_pipeline(url, tmpdir, progress_cb=None):
    """YouTube â†’ demucs â†’ Piano Transcription â†’ Whisper â†’ LilyPond â†’ PDF"""
    def update(msg):
        if progress_cb:
            progress_cb(msg)
        print(f'  {msg}')

    update('â¬‡ï¸ ä¸‹è¼‰éŸ³é »ä¸­...')
    title = yt_get_title(url)
    wav = yt_download_audio(url, tmpdir)

    update('ğŸ›ï¸ Demucs åˆ†é›¢éŸ³è»Œä¸­...')
    stems = separate_stems(wav, tmpdir)

    other_path = stems.get('other')
    vocals_path = stems.get('vocals')

    if not other_path:
        raise RuntimeError('demucs æœªç”¢å‡º other è»Œ')

    update('ğŸ¹ è½‰è­œï¼šä¼´å¥è»Œ...')
    other_midi = os.path.join(tmpdir, 'other.mid')
    transcribe_to_midi(other_path, other_midi)

    vocals_midi = None
    if vocals_path:
        update('ğŸ¤ è½‰è­œï¼šäººè²è»Œ (pyin)...')
        vocals_midi = os.path.join(tmpdir, 'vocals.mid')
        vocals_to_midi_pyin(vocals_path, vocals_midi)

    # Whisper è¾¨è­˜æ­Œè©
    whisper_result = None
    if vocals_path:
        update('ğŸ“ Whisper è¾¨è­˜æ­Œè©ä¸­...')
        try:
            whisper_result = whisper_transcribe(vocals_path, tmpdir)
            lyrics_text = whisper_result.text if hasattr(whisper_result, 'text') else ''
            print(f'  Lyrics: {lyrics_text[:80]}...')
        except Exception as e:
            print(f'  Whisper error: {e}')

    # åˆä½µ MIDI
    merged_midi = os.path.join(tmpdir, 'merged.mid')
    merge_midi(other_midi, vocals_midi, merged_midi)

    update('ğŸ“„ ç”¢ç”Ÿæ¨‚è­œ PDF...')
    ly_path = os.path.join(tmpdir, 'score.ly')
    midi_to_lilypond_full(other_midi, vocals_midi, ly_path, title=title,
                          whisper_result=whisper_result, audio_path=other_path)

    pdf_path = lilypond_to_pdf(ly_path, tmpdir)
    update('âœ… å®Œæˆï¼')
    return pdf_path, merged_midi, title


def jianpu_pipeline(url, tmpdir, progress_cb=None):
    """YouTube â†’ demucs â†’ pyin + chords + Whisper â†’ ç°¡è­œ PDF"""
    def update(msg):
        if progress_cb:
            progress_cb(msg)
        print(f'  {msg}')

    update('â¬‡ï¸ ä¸‹è¼‰éŸ³é »ä¸­...')
    title = yt_get_title(url)
    wav = yt_download_audio(url, tmpdir)

    update('ğŸ›ï¸ Demucs åˆ†é›¢éŸ³è»Œä¸­...')
    stems = separate_stems(wav, tmpdir)
    other_path = stems.get('other')
    vocals_path = stems.get('vocals')
    if not vocals_path:
        raise RuntimeError('demucs æœªç”¢å‡º vocals è»Œ')

    update('ğŸ¤ åµæ¸¬äººè²æ—‹å¾‹ (pyin)...')
    vocals_midi = os.path.join(tmpdir, 'vocals_jianpu.mid')
    vocals_to_midi_pyin(vocals_path, vocals_midi)

    vm = pretty_midi.PrettyMIDI(vocals_midi)
    vocal_notes = []
    for inst in vm.instruments:
        if not inst.is_drum:
            vocal_notes.extend(inst.notes)
    vocal_notes.sort(key=lambda n: n.start)

    # åµæ¸¬èª¿æ€§å’Œ BPM
    ref_audio = other_path or vocals_path
    y_ref, sr_ref = librosa.load(ref_audio, sr=22050, mono=True)
    update('ğŸ” åµæ¸¬èª¿æ€§å’Œ BPM...')
    key_str = detect_key(y_ref, sr_ref)
    bpm_val = detect_bpm(y_ref, sr_ref)
    print(f'  Key: {key_str}, BPM: {bpm_val}')

    update('ğŸ¸ åµæ¸¬å’Œå¼¦...')
    chords = detect_chords(ref_audio, bpm_val)

    whisper_result = None
    update('ğŸ“ Whisper è¾¨è­˜æ­Œè©ä¸­...')
    try:
        whisper_result = whisper_transcribe(vocals_path, tmpdir)
    except Exception as e:
        print(f'  Whisper error: {e}')

    update('ğŸ¼ ç”¢ç”Ÿç°¡è­œ PDF...')
    jianpu_bars = format_jianpu(vocal_notes, chords, key_str, bpm_val, whisper_result)
    pdf_path = os.path.join(tmpdir, 'jianpu.pdf')
    render_jianpu_pdf(jianpu_bars, title, key_str, bpm_val, pdf_path)

    update('âœ… å®Œæˆï¼')
    return pdf_path, title


def whisper_transcribe(audio_path, tmpdir, language=None):
    """ç”¨ OpenAI Whisper API è¾¨è­˜èªéŸ³ï¼Œå›å‚³æ™‚é–“æˆ³ã€‚language=None è‡ªå‹•åµæ¸¬"""
    openai_client = OpenAI()
    compressed = os.path.join(tmpdir, 'whisper_input.mp3')
    subprocess.run(
        ['ffmpeg', '-y', '-i', audio_path, '-ac', '1', '-ar', '16000', '-b:a', '64k', compressed],
        capture_output=True, timeout=60)
    kwargs = dict(model='whisper-1', response_format='verbose_json',
                  timestamp_granularities=['word', 'segment'])
    if language:
        kwargs['language'] = language
    with open(compressed, 'rb') as f:
        result = openai_client.audio.transcriptions.create(file=f, **kwargs)
    return result


def whisper_to_srt(audio_path, output_srt, tmpdir, language='zh'):
    """éŸ³é » â†’ Whisper â†’ SRT å­—å¹•æª”ï¼ˆé è¨­ä¸­æ–‡ï¼‰"""
    result = whisper_transcribe(audio_path, tmpdir, language=language)
    segments = result.segments if hasattr(result, 'segments') else []
    with open(output_srt, 'w', encoding='utf-8') as f:
        for i, seg in enumerate(segments):
            start = seg['start'] if isinstance(seg, dict) else seg.start
            end = seg['end'] if isinstance(seg, dict) else seg.end
            text = seg['text'] if isinstance(seg, dict) else seg.text
            f.write(f"{i+1}\n")
            f.write(f"{_srt_time(start)} --> {_srt_time(end)}\n")
            f.write(f"{text.strip()}\n\n")
    return output_srt


def _srt_time(seconds):
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    ms = int((seconds % 1) * 1000)
    return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"


def video_add_subtitles(video_path, srt_path, output_path):
    """æŠŠ SRT å­—å¹•ç‡’é€²å½±ç‰‡"""
    r = subprocess.run(
        ['ffmpeg', '-y', '-i', video_path, '-vf', f"subtitles={srt_path}",
         '-c:a', 'copy', output_path],
        capture_output=True, text=True, timeout=600)
    if r.returncode != 0:
        raise RuntimeError(f'ffmpeg å­—å¹•åˆæˆå¤±æ•—: {r.stderr[-200:]}')
    return output_path


def yt_download_audio(url, tmpdir):
    output_path = os.path.join(tmpdir, 'audio.%(ext)s')
    r = subprocess.run(
        ['yt-dlp', '-x', '--audio-format', 'wav', '--audio-quality', '0',
         '-o', output_path, '--no-playlist', url],
        capture_output=True, text=True, timeout=300)
    if r.returncode != 0:
        raise RuntimeError(f'yt-dlp å¤±æ•—: {r.stderr[-300:]}')
    for f in os.listdir(tmpdir):
        if f.startswith('audio.'):
            return os.path.join(tmpdir, f)
    raise RuntimeError('ä¸‹è¼‰å¤±æ•—ï¼šæ‰¾ä¸åˆ°éŸ³é »æª”')


def separate_stems(wav_path, tmpdir):
    """ç”¨ demucs åˆ†é›¢ 4 è»Œï¼švocals, drums, bass, other"""
    print('  Separating stems with demucs (4 stems)...')
    r = subprocess.run(
        ['python', '-m', 'demucs', '-o', tmpdir, '--mp3', wav_path],
        capture_output=True, text=True, timeout=1200)
    if r.returncode != 0:
        print(f'  demucs warning: {r.stderr[-200:]}')

    base = os.path.splitext(os.path.basename(wav_path))[0]
    stems = {}
    stem_names = ['vocals', 'drums', 'bass', 'other']

    # æ‰¾ demucs è¼¸å‡ºç›®éŒ„
    for model_dir in ['htdemucs', 'htdemucs_ft', 'mdx_extra']:
        stem_dir = os.path.join(tmpdir, model_dir, base)
        if os.path.isdir(stem_dir):
            for name in stem_names:
                for ext in ['.mp3', '.wav']:
                    p = os.path.join(stem_dir, name + ext)
                    if os.path.exists(p):
                        stems[name] = p
                        print(f'    {name}: {os.path.getsize(p)/1024:.0f} KB')
            break

    if not stems:
        raise RuntimeError('demucs æœªç”¢å‡ºåˆ†é›¢éŸ³è»Œ')

    print(f'  åˆ†é›¢å®Œæˆï¼Œå…± {len(stems)} è»Œ')
    return stems


def detect_key(y, sr):
    """ç”¨ chroma + Krumhansl-Kessler åµæ¸¬èª¿æ€§"""
    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
    chroma_avg = chroma.mean(axis=1)

    major_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09,
                              2.52, 5.19, 2.39, 3.66, 2.29, 2.88])
    minor_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53,
                              2.54, 4.75, 3.98, 2.69, 3.34, 3.17])

    NAMES = ['C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']
    best_corr, best_key, best_mode = -2, 0, 'major'

    for shift in range(12):
        rolled = np.roll(chroma_avg, -shift)
        corr_maj = np.corrcoef(rolled, major_profile)[0, 1]
        corr_min = np.corrcoef(rolled, minor_profile)[0, 1]
        if corr_maj > best_corr:
            best_corr, best_key, best_mode = corr_maj, shift, 'major'
        if corr_min > best_corr:
            best_corr, best_key, best_mode = corr_min, shift, 'minor'

    return f'{NAMES[best_key]} {best_mode}'


def detect_bpm(y, sr):
    """åµæ¸¬ BPM"""
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
    if hasattr(tempo, '__len__'):
        tempo = tempo[0]
    return int(round(tempo))


def _tokenize(text):
    """CJK é€å­—ã€è‹±æ–‡ä¿æŒæ•´å­—"""
    tokens = []
    word = ''
    for ch in text:
        if ('\u4e00' <= ch <= '\u9fff' or '\u3040' <= ch <= '\u30ff'
                or '\u31f0' <= ch <= '\u31ff' or '\uff00' <= ch <= '\uffef'
                or '\u3400' <= ch <= '\u4dbf' or '\uac00' <= ch <= '\ud7af'):
            if word.strip():
                tokens.append(word.strip())
                word = ''
            tokens.append(ch)
        elif ch in (' ', '\n', '\t'):
            if word.strip():
                tokens.append(word.strip())
                word = ''
        else:
            word += ch
    if word.strip():
        tokens.append(word.strip())
    return tokens


def detect_chords(audio_path, bpm):
    """ç”¨ chroma åµæ¸¬å’Œå¼¦ï¼ˆæ¯å°ç¯€ä¸€å€‹ï¼‰"""
    y, sr = librosa.load(audio_path, sr=22050, mono=True)
    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
    beat_sec = 60.0 / bpm
    bar_sec = beat_sec * 4
    times = librosa.times_like(chroma, sr=sr)
    if len(times) == 0:
        return []
    total_dur = times[-1]

    NAMES = ['C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']
    major_t = np.array([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], dtype=float)
    minor_t = np.array([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], dtype=float)

    chords = []
    t = 0.0
    while t < total_dur:
        t_end = min(t + bar_sec, total_dur)
        mask = (times >= t) & (times < t_end)
        if mask.sum() == 0:
            t = t_end
            continue
        avg = chroma[:, mask].mean(axis=1)
        best, name = -1, 'C'
        for s in range(12):
            for tmpl, suffix in [(major_t, ''), (minor_t, 'm')]:
                rolled = np.roll(tmpl, s)
                denom = np.linalg.norm(avg) * np.linalg.norm(rolled)
                score = np.dot(avg, rolled) / denom if denom > 0 else 0
                if score > best:
                    best, name = score, NAMES[s] + suffix
        chords.append((t, t_end, name))
        t = t_end

    print(f'  Detected {len(chords)} chords')
    return chords


def format_jianpu(vocal_notes, chords, key_str, bpm, whisper_result):
    """äººè²éŸ³ç¬¦+å’Œå¼¦+æ­Œè© â†’ ç°¡è­œæ ¼å¼ (bars list)"""
    root_name = key_str.split()[0]
    ROOT_MAP = {'C': 0, 'C#': 1, 'Db': 1, 'D': 2, 'D#': 3, 'Eb': 3,
                'E': 4, 'F': 5, 'F#': 6, 'Gb': 6, 'G': 7, 'G#': 8,
                'Ab': 8, 'A': 9, 'A#': 10, 'Bb': 10, 'B': 11}
    root_pc = ROOT_MAP.get(root_name, 0)

    is_minor = 'minor' in key_str.lower()
    DEGREE_MAJOR = ['1', '#1', '2', '#2', '3', '4', '#4', '5', '#5', '6', '#6', '7']
    DEGREE_MINOR = ['1', '#1', '2', 'b3', '3', '4', '#4', '5', 'b6', '6', 'b7', '7']
    DEGREE = DEGREE_MINOR if is_minor else DEGREE_MAJOR

    # ä¸»éŸ³å…«åº¦ï¼ˆå–äººè²ä¸­ä½æ•¸æ‰€åœ¨å…«åº¦ï¼‰
    if vocal_notes:
        med = sorted(n.pitch for n in vocal_notes)[len(vocal_notes) // 2]
        home_oct = med // 12
    else:
        home_oct = 5

    def pitch_to_deg(midi_pitch):
        sem = (midi_pitch % 12 - root_pc) % 12
        deg = DEGREE[sem]
        home_base = home_oct * 12 + root_pc
        oct_shift = (midi_pitch - home_base) // 12
        return deg, oct_shift

    beat_sec = 60.0 / bpm
    eighth = beat_sec / 2
    bar_sec = beat_sec * 4

    total_dur = max(
        (max(n.end for n in vocal_notes) if vocal_notes else 0),
        (max(c[1] for c in chords) if chords else 0),
        bar_sec)
    total_bars = int(total_dur / bar_sec) + 1
    slots_total = total_bars * 8

    # å»ºç«‹ grid
    grid = [{'note': '0', 'oct': 0, 'onset': False, 'lyric': ''}
            for _ in range(slots_total)]

    for note in vocal_notes:
        s_start = int(round(note.start / eighth))
        s_end = int(round(note.end / eighth))
        s_start = max(0, min(s_start, slots_total - 1))
        s_end = max(s_start + 1, min(s_end, slots_total))

        deg, oct_diff = pitch_to_deg(note.pitch)
        grid[s_start] = {'note': deg, 'oct': oct_diff, 'onset': True, 'lyric': ''}
        for s in range(s_start + 1, s_end):
            if s < slots_total and grid[s]['note'] == '0':
                grid[s] = {'note': '-', 'oct': 0, 'onset': False, 'lyric': ''}

    # æ­Œè©å°é½Š
    if whisper_result:
        segments = []
        raw_segs = getattr(whisper_result, 'segments', [])
        for seg in raw_segs:
            if isinstance(seg, dict):
                segments.append((seg['start'], seg['end'], seg['text'].strip()))
            else:
                segments.append((seg.start, seg.end, seg.text.strip()))

        timed_tokens = []
        for seg_s, seg_e, text in segments:
            tokens = _tokenize(text)
            if not tokens:
                continue
            dt = (seg_e - seg_s) / max(len(tokens), 1)
            for i, tok in enumerate(tokens):
                timed_tokens.append((seg_s + i * dt, tok))

        ci = 0
        for s in range(slots_total):
            if not grid[s]['onset']:
                continue
            t = s * eighth
            while ci < len(timed_tokens) and timed_tokens[ci][0] < t - 0.8:
                ci += 1
            if ci < len(timed_tokens) and abs(timed_tokens[ci][0] - t) < 1.5:
                grid[s]['lyric'] = timed_tokens[ci][1]
                ci += 1

    # å’Œå¼¦å°é½Šåˆ°å°ç¯€
    bar_chords = [''] * total_bars
    for start, end, name in chords:
        idx = int(start / bar_sec)
        if 0 <= idx < total_bars:
            bar_chords[idx] = name

    # çµ„è£ bars
    bars = []
    for b in range(total_bars):
        slots = grid[b * 8: b * 8 + 8]
        bars.append({'chord': bar_chords[b], 'slots': slots})

    return bars


def render_jianpu_pdf(bars, title, key_str, bpm, output_pdf):
    """ç°¡è­œè³‡æ–™ â†’ PDFï¼ˆmatplotlibï¼‰"""
    import matplotlib
    matplotlib.use('Agg')
    matplotlib.rcParams['font.sans-serif'] = [
        'PingFang TC', 'Hiragino Sans', 'Arial Unicode MS',
        'Noto Sans CJK TC', 'SimHei', 'sans-serif']
    matplotlib.rcParams['axes.unicode_minus'] = False
    import matplotlib.pyplot as plt
    from matplotlib.backends.backend_pdf import PdfPages

    root_name = key_str.split()[0]
    BARS_PER_LINE = 2

    # A4 page (inches)
    pw, ph = 8.27, 11.69
    ml, mr, mt, mb = 0.8, 0.6, 0.5, 0.5
    usable_w = pw - ml - mr

    bar_w = usable_w / BARS_PER_LINE
    slot_w = bar_w / 8

    chord_h = 0.22
    note_h = 0.30
    lyric_h = 0.25
    group_gap = 0.18
    group_h = chord_h + note_h + lyric_h + group_gap

    title_block_h = 0.9
    lines_p1 = int((ph - mt - mb - title_block_h) / group_h)
    lines_pn = int((ph - mt - mb) / group_h)

    # å»æ‰å°¾éƒ¨ç©ºç™½å°ç¯€
    while len(bars) > 1 and all(s['note'] == '0' for s in bars[-1]['slots']):
        bars.pop()
    total_lines = (len(bars) + BARS_PER_LINE - 1) // BARS_PER_LINE

    with PdfPages(output_pdf) as pdf:
        li = 0
        pg = 0
        while li < total_lines:
            fig = plt.figure(figsize=(pw, ph))
            ax = fig.add_axes([0, 0, 1, 1])
            ax.set_xlim(0, pw)
            ax.set_ylim(0, ph)
            ax.axis('off')

            if pg == 0:
                y = ph - mt - 0.15
                ax.text(pw / 2, y, title, ha='center', va='top',
                        fontsize=18, fontweight='bold')
                y -= 0.4
                ax.text(pw / 2, y, f'1={root_name}    {bpm} BPM    4/4',
                        ha='center', va='top', fontsize=12, color='#555')
                y -= 0.45
                max_lines = lines_p1
            else:
                y = ph - mt
                max_lines = lines_pn

            for _ in range(max_lines):
                if li >= total_lines:
                    break

                bs = li * BARS_PER_LINE
                be = min(bs + BARS_PER_LINE, len(bars))
                n_bars = be - bs

                yc = y
                yn = y - chord_h
                yl = y - chord_h - note_h

                # å°ç¯€ç·š
                for i in range(n_bars + 1):
                    x = ml + i * bar_w
                    lw = 1.5 if (bs + i == len(bars)) else 0.8
                    ax.plot([x, x], [yc + 0.1, yl - 0.1], 'k-', lw=lw)

                for bi in range(bs, be):
                    bar = bars[bi]
                    bx = ml + (bi - bs) * bar_w

                    if bar['chord']:
                        ax.text(bx + 0.08, yc, bar['chord'],
                                ha='left', va='top', fontsize=10,
                                fontweight='bold', style='italic', color='#333')

                    for si, slot in enumerate(bar['slots']):
                        sx = bx + si * slot_w + slot_w / 2
                        note = slot['note']
                        if note not in ('0', '-'):
                            ax.text(sx, yn, note, ha='center', va='top',
                                    fontsize=14, fontweight='bold')
                            oc = slot['oct']
                            if oc > 0:
                                for d in range(oc):
                                    ax.plot(sx, yn + 0.08 + d * 0.07,
                                            'ko', markersize=3)
                            elif oc < 0:
                                for d in range(-oc):
                                    ax.plot(sx, yn - 0.25 - d * 0.07,
                                            'ko', markersize=3)
                        elif note == '-':
                            ax.text(sx, yn, '-', ha='center', va='top',
                                    fontsize=14, color='#666')
                        else:
                            ax.text(sx, yn, '0', ha='center', va='top',
                                    fontsize=14, color='#ccc')

                        if slot.get('lyric'):
                            ax.text(sx, yl, slot['lyric'],
                                    ha='center', va='top', fontsize=10)

                y -= group_h
                li += 1

            pdf.savefig(fig)
            plt.close(fig)
            pg += 1

    print(f'  Jianpu PDF: {total_lines} lines, {pg} pages')
    return output_pdf


def align_lyrics_to_notes(whisper_result, vocal_notes):
    """ç”¨ Whisper æ™‚é–“æˆ³æŠŠæ­Œè©å°é½Šåˆ°äººè²éŸ³ç¬¦ï¼ˆå…©æŒ‡é‡æƒæï¼‰"""
    if not whisper_result or not vocal_notes:
        return []

    segments = []
    raw_segments = getattr(whisper_result, 'segments', [])
    for seg in raw_segments:
        if isinstance(seg, dict):
            segments.append((seg['start'], seg['end'], seg['text'].strip()))
        else:
            segments.append((seg.start, seg.end, seg.text.strip()))

    if not segments:
        return []

    timed_chars = []
    for seg_start, seg_end, text in segments:
        tokens = _tokenize(text)
        if not tokens:
            continue
        tok_dur = (seg_end - seg_start) / max(len(tokens), 1)
        for i, tok in enumerate(tokens):
            timed_chars.append((seg_start + i * tok_dur, tok))

    if not timed_chars:
        return []

    # å…©æŒ‡é‡å°é½Šï¼šæ¯å€‹éŸ³ç¬¦æ‰¾æœ€è¿‘çš„æœªä½¿ç”¨å­—å…ƒ
    result = []
    ci = 0
    for note in vocal_notes:
        # è·³éæ™‚é–“ä¸Šå¤ªæ—©çš„å­—å…ƒ
        while ci < len(timed_chars) and timed_chars[ci][0] < note.start - 0.8:
            ci += 1

        if ci < len(timed_chars) and abs(timed_chars[ci][0] - note.start) < 1.5:
            tok = timed_chars[ci][1]
            safe_tok = tok.replace('"', '').replace('\\', '').replace('{', '').replace('}', '')
            result.append(f'"{safe_tok}"' if safe_tok else '_')
            ci += 1
        else:
            result.append('_')

    return result


def midi_to_lilypond_full(other_midi, vocals_midi, ly_path, title='Score',
                          whisper_result=None, audio_path=None):
    """MIDI â†’ LilyPond ç¸½è­œï¼ˆäººè²+æ­Œè© + é‹¼ç´å·¦å³æ‰‹ï¼Œå«å’Œå¼¦+ä¼‘æ­¢ç¬¦+èª¿æ€§ï¼‰"""

    def get_notes(midi_path):
        midi = pretty_midi.PrettyMIDI(midi_path)
        notes = []
        for inst in midi.instruments:
            if not inst.is_drum:
                notes.extend(inst.notes)
        notes.sort(key=lambda n: (n.start, n.pitch))
        return notes, midi

    other_notes, other_pm = get_notes(other_midi)

    tempo_times, tempos = other_pm.get_tempo_changes()
    bpm = int(tempos[0]) if len(tempos) > 0 else 120
    beat_sec = 60.0 / bpm

    # èª¿æ€§åµæ¸¬
    key_str = 'C major'
    if audio_path:
        try:
            y_key, sr_key = librosa.load(audio_path, sr=22050, mono=True)
            key_str = detect_key(y_key, sr_key)
            print(f'  Detected key: {key_str}')
        except Exception as e:
            print(f'  Key detection failed: {e}')

    FLAT_KEYS = {'F major', 'Bb major', 'Eb major', 'Ab major', 'Db major', 'Gb major',
                 'D minor', 'G minor', 'C minor', 'F minor', 'Bb minor', 'Eb minor'}
    use_flats = key_str in FLAT_KEYS

    SHARP_NAMES = ['c', 'cis', 'd', 'dis', 'e', 'f', 'fis', 'g', 'gis', 'a', 'ais', 'b']
    FLAT_NAMES = ['c', 'des', 'd', 'ees', 'e', 'f', 'ges', 'g', 'aes', 'a', 'bes', 'b']
    note_names = FLAT_NAMES if use_flats else SHARP_NAMES

    KEY_MAP = {
        'C major': 'c \\major', 'G major': 'g \\major', 'D major': 'd \\major',
        'A major': 'a \\major', 'E major': 'e \\major', 'B major': 'b \\major',
        'F major': 'f \\major', 'Bb major': 'bes \\major', 'Eb major': 'ees \\major',
        'Ab major': 'aes \\major', 'Db major': 'des \\major', 'Gb major': 'ges \\major',
        'F# major': 'fis \\major', 'C# major': 'cis \\major',
        'A minor': 'a \\minor', 'E minor': 'e \\minor', 'B minor': 'b \\minor',
        'F# minor': 'fis \\minor', 'C# minor': 'cis \\minor', 'G# minor': 'gis \\minor',
        'D minor': 'd \\minor', 'G minor': 'g \\minor', 'C minor': 'c \\minor',
        'F minor': 'f \\minor', 'Bb minor': 'bes \\minor', 'Eb minor': 'ees \\minor',
    }
    ly_key = KEY_MAP.get(key_str, 'c \\major')

    def pitch_to_lily(p):
        octave = (p // 12) - 1
        name = note_names[p % 12]
        diff = octave - 3
        if diff > 0:
            name += "'" * diff
        elif diff < 0:
            name += "," * abs(diff)
        return name

    def beats_to_lily_dur(beats):
        if beats >= 3.5: return '1'
        elif beats >= 1.75: return '2'
        elif beats >= 1.2: return '4.'
        elif beats >= 0.875: return '4'
        elif beats >= 0.625: return '8.'
        elif beats >= 0.4375: return '8'
        elif beats >= 0.21875: return '16'
        else: return '32'

    def fill_rests(beats):
        if beats <= 0.1:
            return ''
        parts = []
        remaining = beats
        for val, name in [(4.0, 'r1'), (2.0, 'r2'), (1.0, 'r4'), (0.5, 'r8'), (0.25, 'r16')]:
            while remaining >= val - 0.05:
                parts.append(name)
                remaining -= val
        return ' '.join(parts)

    def notes_to_str(note_list):
        """éŸ³ç¬¦åˆ—è¡¨ â†’ LilyPond å­—ä¸²ï¼ˆå«å’Œå¼¦åˆ†çµ„+ä¼‘æ­¢ç¬¦+å°ç¯€ç·šï¼‰"""
        if not note_list:
            return 'R1*4'

        # æŒ‰èµ·å§‹æ™‚é–“åˆ†çµ„ï¼ˆåŒæ™‚é–“çš„éŸ³çµ„æˆå’Œå¼¦ï¼‰
        CHORD_TOL = 0.05  # ç§’
        sorted_notes = sorted(note_list, key=lambda n: (n.start, n.pitch))
        groups = []
        i = 0
        while i < len(sorted_notes):
            group = [sorted_notes[i]]
            j = i + 1
            while j < len(sorted_notes) and abs(sorted_notes[j].start - sorted_notes[i].start) < CHORD_TOL:
                group.append(sorted_notes[j])
                j += 1
            groups.append(group)
            i = j

        bar_dur = 4 * beat_sec  # ä¸€å°ç¯€çš„ç§’æ•¸
        next_bar = bar_dur      # ä¸‹ä¸€å€‹å°ç¯€ç·šçš„æ™‚é–“
        parts = ['\\cadenzaOn']
        cursor = 0.0

        for group in groups:
            gap = group[0].start - cursor
            if gap > beat_sec * 0.2:
                gap_beats = gap / beat_sec
                rest = fill_rests(gap_beats)
                if rest:
                    parts.append(rest)

            min_dur = min(n.end - n.start for n in group)
            dur_beats = min_dur / beat_sec
            dur_str = beats_to_lily_dur(dur_beats)

            if len(group) == 1:
                parts.append(f'{pitch_to_lily(group[0].pitch)}{dur_str}')
            else:
                pitches = ' '.join(pitch_to_lily(n.pitch)
                                   for n in sorted(group, key=lambda n: n.pitch))
                parts.append(f'<{pitches}>{dur_str}')

            cursor = max(n.end for n in group)

            # æ¯éš”ä¸€å°ç¯€æ’å…¥å°ç¯€ç·šï¼ˆè®“ LilyPond æ›è¡Œï¼‰
            while cursor >= next_bar - 0.05:
                parts.append('\\bar "|"')
                next_bar += bar_dur

        parts.append('\\bar "|."')
        return ' '.join(parts)

    # ç”¨ä¸­å¤® C (MIDI 60) åˆ†å·¦å³æ‰‹
    right = [n for n in other_notes if n.pitch >= 60]
    left = [n for n in other_notes if n.pitch < 60]

    # Vocals
    vocal_notes = []
    if vocals_midi:
        vocal_notes, _ = get_notes(vocals_midi)

    # æ­Œè©ï¼ˆç”¨ Whisper æ™‚é–“æˆ³å°é½Šï¼‰
    lyrics_block = ''
    if whisper_result and vocal_notes:
        ly_words = align_lyrics_to_notes(whisper_result, vocal_notes)
        # å»æ‰å°¾éƒ¨é€£çºŒçš„ _
        while ly_words and ly_words[-1] == '_':
            ly_words.pop()
        if ly_words:
            lyrics_block = '\\new Lyrics \\lyricsto "vox" { ' + ' '.join(ly_words) + ' }'

    safe_title = re.sub(r'[\\\"{}]', '', title)
    ly = f'''\\version "2.24.0"
\\header {{
  title = "{safe_title}"
  subtitle = "AI-transcribed from YouTube â€” {key_str}"
  tagline = "Generated by Music Grab Bot"
}}
\\paper {{
  #(set-paper-size "a4")
  top-margin = 10
  bottom-margin = 10
  left-margin = 12
  right-margin = 12
}}
\\score {{
  <<
    \\new Staff = "vocals" \\with {{ instrumentName = "Vocals" }} {{
      \\clef treble
      \\key {ly_key}
      \\time 4/4
      \\tempo 4 = {bpm}
      \\new Voice = "vox" {{ {notes_to_str(vocal_notes)} }}
    }}
    {lyrics_block}
    \\new PianoStaff \\with {{ instrumentName = "Piano" }} <<
      \\new Staff = "right" {{
        \\clef treble
        \\key {ly_key}
        \\time 4/4
        {{ {notes_to_str(right)} }}
      }}
      \\new Staff = "left" {{
        \\clef bass
        \\key {ly_key}
        \\time 4/4
        {{ {notes_to_str(left)} }}
      }}
    >>
  >>
  \\layout {{
    indent = 15\\mm
    short-indent = 5\\mm
  }}
}}
'''
    with open(ly_path, 'w') as f:
        f.write(ly)
    n_lyrics = len(getattr(whisper_result, 'text', '')) if whisper_result else 0
    print(f'  LilyPond: vocals={len(vocal_notes)}, RH={len(right)}, LH={len(left)}, lyrics={n_lyrics} chars')


def lilypond_to_pdf(ly_path, tmpdir):
    r = subprocess.run(
        ['lilypond', '-dno-point-and-click', '-o', os.path.join(tmpdir, 'score'), ly_path],
        capture_output=True, text=True, timeout=600)
    pdf_path = os.path.join(tmpdir, 'score.pdf')
    if not os.path.exists(pdf_path):
        raise RuntimeError(f'LilyPond ç·¨è­¯å¤±æ•—: {r.stderr[-500:]}')
    return pdf_path


def sheet_pipeline(url, tmpdir):
    title = yt_get_title(url)
    print(f'  Title: {title}')

    # 1. YouTube â†’ WAV
    wav = yt_download_audio(url, tmpdir)
    print(f'  Audio: {wav}')

    # 2. demucs åˆ†é›¢ 4 è»Œ
    stems = separate_stems(wav, tmpdir)

    return stems, title


# â”€â”€ Discord Events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@client.event
async def on_ready():
    print(f'Bot å·²ä¸Šç·š: {client.user}')
    print('  åŠŸèƒ½: PDF/DOCXâ†’èªéŸ³, YouTubeâ†’æ¨‚è­œ')


@client.event
async def on_message(message):
    if message.author == client.user or message.author.bot:
        return

    content = message.content.strip()
    loop = asyncio.get_event_loop()
    print(f'  [MSG] {message.author}: {content[:80]}')

    # â”€â”€ !pdf â†’ demucs + Piano Transcription + LilyPond â”€â”€
    # â”€â”€ !help â†’ åŠŸèƒ½èªªæ˜ â”€â”€
    if content.lower() in ('!help', '!æŒ‡ä»¤', '!commands'):
        help_text = """**ğŸµ Music Grab Bot æŒ‡ä»¤èªªæ˜**

ğŸ“¥ **ä¸‹è¼‰**
`YouTube URL` â†’ ç›´æ¥ä¸‹è¼‰ MP3
`!video <URL>` â†’ ä¸‹è¼‰å½±ç‰‡ MP4

ğŸ¼ **éŸ³æ¨‚è™•ç†**
`!dep <URL>` â†’ Demucs åˆ†é›¢å››è»Œï¼ˆäººè²/é¼“/è²æ–¯/å…¶ä»–ï¼‰
`!midi <URL>` â†’ è½‰ MIDIï¼ˆäººè²+ä¼´å¥ï¼‰
`!pdf <URL>` â†’ è½‰æ¨‚è­œ PDFï¼ˆå«æ­Œè©ï¼‰
`!jianpu <URL>` â†’ è½‰ç°¡è­œ PDFï¼ˆæ•¸å­—è­œ+å’Œå¼¦+æ­Œè©ï¼‰

ğŸ“ **å­—å¹•**
ä¸Šå‚³ MP4/MKV/AVI â†’ Whisper è‡ªå‹•è¾¨è­˜ â†’ SRT å­—å¹•æª”

ğŸ”Š **æ–‡ä»¶è½‰èªéŸ³**
ä¸Šå‚³ PDF æˆ– DOCX â†’ AI æ‘˜è¦ â†’ MP3 èªéŸ³

ğŸ’¡ æ‰€æœ‰ YouTube æŒ‡ä»¤æ”¯æ´ youtube.com å’Œ youtu.be é€£çµ"""
        await message.channel.send(help_text)
        return

    # â”€â”€ æŒ‡ä»¤åˆ¤æ–· â”€â”€
    is_video_cmd = content.lower().startswith('!video')
    is_dep_cmd = content.lower().startswith('!dep')
    is_pdf_cmd = content.lower().startswith('!pdf')
    is_midi_cmd = content.lower().startswith('!midi')
    is_jianpu_cmd = content.lower().startswith('!jianpu')
    yt_match = YT_URL_PATTERN.search(content)

    if is_video_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        await message.channel.send('ä¸‹è¼‰å½±ç‰‡ä¸­...')
        tmpdir = tempfile.mkdtemp()
        try:
            title = await loop.run_in_executor(None, yt_get_title, url)
            video_path = await loop.run_in_executor(None, yt_download_video, url, tmpdir)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'video'

            fsize = os.path.getsize(video_path)
            print(f'  Video: {fsize/1024/1024:.1f} MB')
            if fsize <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'**{title}**',
                    file=discord.File(video_path, filename=f'{safe_name}.mp4'))
            else:
                await message.channel.send(f'å½±ç‰‡ {fsize/1024/1024:.1f} MBï¼Œä¸Šå‚³åˆ° GitHub...')
                ts_name = f'video_{int(time.time())}.mp4'
                dl_url = await loop.run_in_executor(
                    None, upload_to_github, video_path, ts_name)
                await message.channel.send(f'**{title}**\n{dl_url}')
        except Exception as e:
            await message.channel.send(f'ä¸‹è¼‰å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    if is_pdf_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        progress_msg = await message.channel.send('ğŸµ é–‹å§‹è½‰æ¨‚è­œ...')
        tmpdir = tempfile.mkdtemp()
        try:
            # ç”¨ progress callback æ›´æ–° Discord è¨Šæ¯
            progress_state = {'msg': progress_msg, 'loop': loop}

            def _update_progress(text):
                asyncio.run_coroutine_threadsafe(
                    progress_state['msg'].edit(content=text),
                    progress_state['loop'])

            pdf_path, midi_path, title = await loop.run_in_executor(
                None, pdf_pipeline, url, tmpdir, _update_progress)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'score'
            # PDF
            pdf_size = os.path.getsize(pdf_path)
            if pdf_size <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'**{title}** æ¨‚è­œï¼š',
                    file=discord.File(pdf_path, filename=f'{safe_name}.pdf'))
            else:
                ts_name = f'score_{int(time.time())}.pdf'
                dl_url = await loop.run_in_executor(
                    None, upload_to_github, pdf_path, ts_name)
                await message.channel.send(f'**{title}** æ¨‚è­œï¼š\n{dl_url}')
            # MIDI
            midi_size = os.path.getsize(midi_path)
            if midi_size <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'MIDIï¼š',
                    file=discord.File(midi_path, filename=f'{safe_name}.mid'))
            else:
                ts_name = f'midi_{int(time.time())}.mid'
                dl_url = await loop.run_in_executor(
                    None, upload_to_github, midi_path, ts_name)
                await message.channel.send(f'MIDIï¼š\n{dl_url}')
        except Exception as e:
            await message.channel.send(f'è½‰è­œå¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    if is_jianpu_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        progress_msg = await message.channel.send('ğŸµ é–‹å§‹è½‰ç°¡è­œ...')
        tmpdir = tempfile.mkdtemp()
        try:
            progress_state = {'msg': progress_msg, 'loop': loop}

            def _update_jianpu(text):
                asyncio.run_coroutine_threadsafe(
                    progress_state['msg'].edit(content=text),
                    progress_state['loop'])

            pdf_path, title = await loop.run_in_executor(
                None, jianpu_pipeline, url, tmpdir, _update_jianpu)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'jianpu'

            pdf_size = os.path.getsize(pdf_path)
            if pdf_size <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'**{title}** ç°¡è­œï¼š',
                    file=discord.File(pdf_path, filename=f'{safe_name}_jianpu.pdf'))
            else:
                ts_name = f'jianpu_{int(time.time())}.pdf'
                dl_url = await loop.run_in_executor(
                    None, upload_to_github, pdf_path, ts_name)
                await message.channel.send(f'**{title}** ç°¡è­œï¼š\n{dl_url}')
        except Exception as e:
            await message.channel.send(f'ç°¡è­œè½‰è­œå¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    if is_midi_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        await message.channel.send('é–‹å§‹è½‰ MIDIï¼ˆä¸‹è¼‰ â†’ åˆ†é›¢éŸ³è»Œ â†’ è½‰è­œï¼‰ï¼Œéœ€è¦å¹¾åˆ†é˜...')
        tmpdir = tempfile.mkdtemp()
        try:
            other_midi, vocals_midi, title = await loop.run_in_executor(
                None, midi_pipeline, url, tmpdir)
            merged = os.path.join(tmpdir, 'merged.mid')
            merge_midi(other_midi, vocals_midi, merged)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'midi'
            await message.channel.send(
                content=f'**{title}** MIDIï¼ˆäººè²+ä¼´å¥ï¼‰ï¼š',
                file=discord.File(merged, filename=f'{safe_name}.mid'))
        except Exception as e:
            await message.channel.send(f'è½‰è­œå¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    # â”€â”€ !dep â†’ demucs åˆ†é›¢å››è»Œ â”€â”€
    if is_dep_cmd and yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        await message.channel.send('æ”¶åˆ° YouTube é€£çµï¼Œé–‹å§‹åˆ†é›¢éŸ³è»Œï¼ˆéœ€è¦å¹¾åˆ†é˜ï¼‰...')
        tmpdir = tempfile.mkdtemp()
        try:
            stems, title = await loop.run_in_executor(
                None, sheet_pipeline, url, tmpdir)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'audio'

            stem_labels = {
                'vocals': 'ğŸ¤ äººè²', 'drums': 'ğŸ¥ é¼“',
                'bass': 'ğŸ¸ è²æ–¯', 'other': 'ğŸ¹ å…¶ä»–æ¨‚å™¨'
            }
            for stem_name, stem_path in stems.items():
                label = stem_labels.get(stem_name, stem_name)
                await message.channel.send(
                    content=f'**{title}** â€” {label}ï¼š',
                    file=discord.File(stem_path, filename=f'{safe_name}_{stem_name}.mp3'))
            await message.channel.send('åˆ†é›¢å®Œæˆï¼')
        except Exception as e:
            await message.channel.send(f'åˆ†é›¢å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    # â”€â”€ ç›´æ¥è²¼ URL â†’ ä¸‹è¼‰ MP3 â”€â”€
    if yt_match:
        url = yt_match.group(0)
        if not url.startswith('http'):
            url = 'https://' + url

        await message.channel.send('ä¸‹è¼‰ MP3 ä¸­...')
        tmpdir = tempfile.mkdtemp()
        try:
            title = await loop.run_in_executor(None, yt_get_title, url)
            mp3_path = await loop.run_in_executor(None, yt_download_mp3, url, tmpdir)
            safe_name = re.sub(r'[^\w\s\-]', '', title)[:40] or 'audio'
            filename = f'{safe_name}.mp3'

            fsize = os.path.getsize(mp3_path)
            print(f'  MP3: {fsize/1024/1024:.1f} MB')
            if fsize <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'**{title}**',
                    file=discord.File(mp3_path, filename=filename))
            else:
                await message.channel.send(f'æª”æ¡ˆ {fsize/1024/1024:.1f} MBï¼Œä¸Šå‚³åˆ° GitHub...')
                ts_name = f'mp3_{int(time.time())}.mp3'
                dl_url = await loop.run_in_executor(
                    None, upload_to_github, mp3_path, ts_name)
                await message.channel.send(f'**{title}**\n{dl_url}')
        except Exception as e:
            await message.channel.send(f'ä¸‹è¼‰å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    # â”€â”€ ä¸Šå‚³ MP4 â†’ Whisper å­—å¹• â”€â”€
    for attachment in message.attachments:
        ext = os.path.splitext(attachment.filename)[1].lower()
        if ext not in VIDEO_EXT:
            continue

        progress_msg = await message.channel.send(f'æ”¶åˆ° `{attachment.filename}`ï¼ŒWhisper å­—å¹•ç”¢ç”Ÿä¸­...')
        tmpdir = tempfile.mkdtemp()
        video_path = os.path.join(tmpdir, attachment.filename)
        await attachment.save(video_path)

        try:
            # æå–éŸ³é »
            audio_path = os.path.join(tmpdir, 'audio.wav')
            await loop.run_in_executor(None, lambda: subprocess.run(
                ['ffmpeg', '-y', '-i', video_path, '-vn', '-ac', '1', '-ar', '16000', audio_path],
                capture_output=True, timeout=120))

            # Whisper
            srt_path = os.path.join(tmpdir, 'subtitles.srt')
            await loop.run_in_executor(None, whisper_to_srt, audio_path, srt_path, tmpdir)

            base_name = os.path.splitext(attachment.filename)[0]
            await message.channel.send(
                content=f'`{attachment.filename}` å­—å¹•ï¼š',
                file=discord.File(srt_path, filename=f'{base_name}.srt'))

            await progress_msg.edit(content='âœ… å­—å¹•ç”¢ç”Ÿå®Œæˆï¼')
        except Exception as e:
            await message.channel.send(f'å­—å¹•å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)
        return

    # â”€â”€ PDF/DOCX â†’ èªéŸ³ â”€â”€
    for attachment in message.attachments:
        ext = os.path.splitext(attachment.filename)[1].lower()
        if ext not in SUPPORTED_EXT:
            continue

        await message.channel.send(f'æ”¶åˆ° `{attachment.filename}`ï¼Œæ­£åœ¨è™•ç†ä¸­...')
        tmpdir = tempfile.mkdtemp()
        input_path = os.path.join(tmpdir, attachment.filename)
        await attachment.save(input_path)

        try:
            if ext == '.docx':
                text = await loop.run_in_executor(None, read_docx, input_path)
            else:
                text = await loop.run_in_executor(None, read_pdf, input_path)

            if not text.strip():
                await message.channel.send('æå–ä¸åˆ°æ–‡å­—ï¼ˆå¯èƒ½æ˜¯æƒææª”ï¼‰ã€‚')
                continue

            await message.channel.send('AI æ­£åœ¨æ¶ˆåŒ–æ–‡ä»¶å…§å®¹...')
            summary = await loop.run_in_executor(None, summarize_text, text)

            chunks = chunk_text(summary)
            base_name = os.path.splitext(attachment.filename)[0]
            await message.channel.send(f'æ‘˜è¦å®Œæˆï¼ˆ{len(summary)} å­—ï¼‰ï¼Œè½‰æ›èªéŸ³ä¸­...')

            merged_path, part_paths = await loop.run_in_executor(
                None, functools.partial(convert_all_chunks, chunks, tmpdir))

            merged_size = os.path.getsize(merged_path)
            if merged_size <= DISCORD_MAX_BYTES:
                await message.channel.send(
                    content=f'`{attachment.filename}` çš„èªéŸ³æ‘˜è¦ï¼š',
                    file=discord.File(merged_path, filename=f'{base_name}.mp3'))
            else:
                await message.channel.send(f'åˆä½µæª”å¤ªå¤§ï¼Œåˆ†æ®µä¸Šå‚³...')
                for i, pp in enumerate(part_paths):
                    await message.channel.send(
                        content=f'èªéŸ³ ({i+1}/{len(part_paths)})',
                        file=discord.File(pp, filename=f'{base_name}_part{i+1}.mp3'))

            await message.channel.send('è½‰æ›å®Œæˆï¼')

        except Exception as e:
            await message.channel.send(f'è½‰æ›å¤±æ•—ï¼š{e}')
        finally:
            shutil.rmtree(tmpdir, ignore_errors=True)


if __name__ == '__main__':
    if not DISCORD_TOKEN:
        print('è«‹è¨­å®šç’°å¢ƒè®Šæ•¸ DISCORD_BOT_TOKEN')
        exit(1)
    client.run(DISCORD_TOKEN)
